input {
  kafka {
    bootstrap_servers => "172.30.32.85:9092,172.30.32.85:9093,172.30.32.85:9094"
    topics => ["tetragon-kafka-adapter-logs"]  # Tetragon Kafka Adapter 日志主题
    group_id => "logstash-k8s-tetragon-kafka-adapter-logs"
    auto_offset_reset => "latest"
    codec => json  # 日志已经是 JSON 格式，直接解析
    # consumer_threads => 8
  }
}

filter {
  # 日志已经是 JSON 格式，不需要 grok 解析
  # 直接使用 JSON codec 解析后的字段
  
  # 处理时间戳字段
  # Tetragon Kafka Adapter 使用 ts 字段（ISO8601 格式）
  if [ts] {
    date {
      match => ["ts", "ISO8601"]
      target => "@timestamp"
    }
  } else if [timestamp] {
    # 备用：如果有 timestamp 字段
    date {
      match => ["timestamp", "ISO8601", "yyyy-MM-dd'T'HH:mm:ss.SSSZ", "yyyy-MM-dd'T'HH:mm:ssZ"]
      target => "@timestamp"
    }
  }
  
  # 如果没有时间戳，使用当前时间
  if ![ts] and ![timestamp] {
    ruby {
      code => "event.set('@timestamp', Time.now)"
    }
  }
  
  # 标准化日志级别字段（确保是大写）
  if [level] {
    mutate {
      uppercase => ["level"]
    }
  }
  
  # 处理消息字段：将 msg 重命名为 message（如果需要）
  if [msg] and ![message] {
    mutate {
      rename => { "msg" => "message" }
    }
  }
  
  # 移除不需要的字段
  mutate {
    remove_field => ["event"]
  }
  
  # 生成索引日期（UTC+8，格式：YYYY.MM.dd）
  ruby {
    code => "event.set('index_date', event.get('@timestamp').time.localtime('+08:00').strftime('%Y.%m.%d'))"
  }
  
  # 添加服务标识
  mutate {
    add_field => { "service" => "tetragon-kafka-adapter" }
    add_field => { "log_type" => "application" }
  }
  
  # 处理 Kubernetes 元数据（如果存在）
  # pod_name, pod_ip, namespace, node_name, node_ip 等字段会直接保留在顶层
  # 如果需要嵌套到 kubernetes 对象中，可以取消下面的注释
  # if [pod_name] {
  #   mutate {
  #     add_field => { 
  #       "[kubernetes][pod][name]" => "%{pod_name}"
  #     }
  #   }
  # }
  # if [pod_ip] {
  #   mutate {
  #     add_field => { 
  #       "[kubernetes][pod][ip]" => "%{pod_ip}"
  #     }
  #   }
  # }
  # if [namespace] {
  #   mutate {
  #     add_field => { 
  #       "[kubernetes][namespace]" => "%{namespace}"
  #     }
  #   }
  # }
  # if [node_name] {
  #   mutate {
  #     add_field => { 
  #       "[kubernetes][node][name]" => "%{node_name}"
  #     }
  #   }
  # }
  # if [node_ip] {
  #   mutate {
  #     add_field => { 
  #       "[kubernetes][node][ip]" => "%{node_ip}"
  #     }
  #   }
  # }
}

output {
  elasticsearch {
    user => "elastic"
    password => "c7jAJ-cA6Lw1MGeByfG9"
    hosts => ["http://172.30.32.71:9200", "http://172.30.32.72:9200", "http://172.30.32.73:9200", "http://172.30.32.74:9200", "http://172.30.32.75:9200"]
    # 使用 index_date 生成索引名称
    index => "tetragon-kafka-adapter-logs-%{index_date}"
  }
  
  #file {
  #  # 使用 server_name 或 pod_name 作为文件名的一部分
  #  path => "/data/logstash/logs/tetragon-kafka-adapter-%{+YYYY.MM.dd}.log"
  #}
  
  # 调试输出（可选，生产环境建议注释掉）
  # stdout {
  #   codec => json
  # }
}
