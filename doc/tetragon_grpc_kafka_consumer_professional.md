# Tetragon gRPC â†’ Kafka Consumerï¼ˆGoï¼‰ä¸“ä¸šçº§æ–¹æ¡ˆï¼ˆé«˜å¹¶å‘/å¯æ‰©å±•/é…ç½®åˆ†ç¦»ï¼‰

> é¢å‘ç”Ÿäº§ï¼šé«˜ååã€å¯æ§èƒŒå‹ã€æ–­çº¿é‡è¿ã€å¯è§‚æµ‹ã€å¯æ¼”è¿›ï¼ˆåæœŸæ–°å¢äº‹ä»¶/å­—æ®µ/Topicï¼‰ã€‚
>
> é€‚ç”¨ï¼šKubernetes ä¸Šè¿è¡Œ Tetragonï¼Œé€šè¿‡ gRPC æµå¼è®¢é˜…äº‹ä»¶ï¼Œå†™å…¥ Kafka ä¾› SIEM / é£æ§ / å®‰å…¨åˆ†æ / å®æ—¶æ£€æµ‹ä½¿ç”¨ã€‚

---

## 1. ç›®æ ‡ä¸çº¦æŸ

### 1.1 ç›®æ ‡
- **ä¸è½ç›˜**ï¼šäº‹ä»¶ä» Tetragon ç›´æ¥è¿›å…¥ Kafkaï¼ˆé¿å… `tetragon.log` æ–‡ä»¶é“¾è·¯ï¼‰ã€‚
- **é«˜å¹¶å‘/é«˜åå**ï¼šæ”¯æ’‘é«˜ QPS äº‹ä»¶æµï¼ˆå°¤å…¶æ˜¯ syscall/kprobe ç±»äº‹ä»¶ï¼‰ã€‚
- **é…ç½®åˆ†ç¦»**ï¼šTopicã€è·¯ç”±ã€é‡‡æ ·ã€èƒŒå‹ç­–ç•¥å…¨éƒ¨åœ¨é…ç½®ä¸­å®šä¹‰ï¼›æ”¯æŒç¯å¢ƒå˜é‡è¦†ç›–ã€‚
- **å¯æ¼”è¿›**ï¼šåæœŸæ–°å¢äº‹ä»¶ç±»å‹ã€å­—æ®µã€Topicï¼Œä¸éœ€è¦å¤§æ”¹æ¶æ„ã€‚
- **å¯è§‚æµ‹**ï¼šå…³é”®æŒ‡æ ‡ï¼ˆååé‡ã€é˜Ÿåˆ—æ°´ä½/å®¹é‡ã€drop/é‡‡æ ·ç»Ÿè®¡ã€å„é˜¶æ®µå¤„ç†å»¶è¿Ÿã€Kafka å†™å…¥å»¶è¿Ÿ/å­—èŠ‚æ•°/é€Ÿç‡ã€Topic çº§åˆ«æŒ‡æ ‡/åˆ†åŒºåˆ†å¸ƒã€DLQ æ­»ä¿¡é˜Ÿåˆ—ç»Ÿè®¡ã€gRPC è¿æ¥çŠ¶æ€/é‡è¿æ¬¡æ•°ã€è§„èŒƒåŒ–/åºåˆ—åŒ–é”™è¯¯ã€æ‰¹å¤„ç†ç»Ÿè®¡ã€Topic ç®¡ç†çŠ¶æ€ã€èµ„æºä½¿ç”¨ç‡ï¼‰ã€‚

### 1.2 çº¦æŸï¼ˆçœŸå®ä¸–ç•Œï¼‰
- Tetragon **ä¸åŸç”Ÿç›´å†™ Kafka**ï¼›æ¨èé€šè¿‡ gRPC è®¢é˜… + ç‹¬ç«‹ Consumerã€‚
- Kafka é›†ç¾¤ååã€Topic åˆ†åŒºæ•°ã€ACK ç­–ç•¥ä¼šå†³å®šä¸Šé™ã€‚
- è‹¥å¼€å¯å¤§é‡ä½å±‚äº‹ä»¶ï¼ˆkprobe/syscallï¼‰ï¼Œäº‹ä»¶é‡å¯èƒ½éå¸¸å¤§ï¼Œéœ€è¦é‡‡æ ·/è¿‡æ»¤/åˆ† topicã€‚

---

## 2. æ€»ä½“æ¶æ„

```
Kernel
  â†“ eBPF
Tetragon (gRPC GetEvents stream)
  â†“ protobuf stream
Go Consumer
  â”œâ”€ Decode + Normalizeï¼ˆprotobuf â†’ ç¨³å®š JSON Schemaï¼‰
  â”œâ”€ Routeï¼ˆæŒ‰äº‹ä»¶ç±»å‹/æ ‡ç­¾æ˜ å°„åˆ° Topicï¼‰
  â”œâ”€ Backpressureï¼ˆé˜Ÿåˆ—/ä¸¢å¼ƒ/é‡‡æ ·ï¼‰
  â””â”€ Kafka Producerï¼ˆæ‰¹é‡+å¹¶å‘+å‹ç¼©ï¼‰
  â†“
Kafka
  â†“
Flink / Spark / SIEM / ES / ClickHouse / Loki / è‡ªç ”æ£€æµ‹
```

---

## 3. æ¨èçš„ç”Ÿäº§çº§å®ç°è¦ç‚¹ï¼ˆæ€§èƒ½ & ç¨³å®šæ€§ï¼‰

### 3.1 å¹¶å‘æ¨¡å‹ï¼ˆæ¨èï¼‰
é‡‡ç”¨ **â€œå• stream è¯»å– + å¤š worker å†™ Kafkaâ€** æˆ– **â€œå¤š stream + å¤š workerâ€**ï¼š

- **Reader**ï¼šè´Ÿè´£ gRPC `Recv()`ï¼Œå°†äº‹ä»¶å¿«é€Ÿå…¥é˜Ÿï¼ˆå°½å¯èƒ½å°‘åšé‡ CPU çš„é€»è¾‘ï¼‰ã€‚
- **Normalizer/Router**ï¼šè½»é‡å­—æ®µæŠ½å–ä¸ topic å†³ç­–ï¼ˆå¯ä¸ Reader åŒçº¿ç¨‹ï¼Œä¹Ÿå¯æ‹†æˆå¤„ç†æ± ï¼‰ã€‚
- **Kafka Writers**ï¼šå¤š worker æ‰¹é‡å†™å…¥ Kafkaï¼ˆæ¯ä¸ª worker æœ‰è‡ªå·±çš„ batch bufferï¼‰ã€‚

> å…¸å‹é…ç½®ï¼š
- writer workersï¼š`min(16, CPUæ ¸æ•°*2)` èµ·æ­¥ï¼Œè§‚å¯Ÿ Kafka broker ä¸ç½‘ç»œç“¶é¢ˆå†è°ƒã€‚
- batchï¼š`max_messages=1000~5000`ï¼Œ`flush_interval=50~200ms`ï¼ˆå–å†³äºå»¶è¿Ÿç›®æ ‡ï¼‰ã€‚
- å‹ç¼©ï¼š`snappy` / `lz4`ï¼ˆååä¼˜å…ˆï¼‰ã€‚

### 3.2 èƒŒå‹ç­–ç•¥ï¼ˆå¿…é¡»æ˜ç¡®ï¼‰
äº‹ä»¶é«˜å³°æ—¶è¦ä¿è¯ consumer ä¸ OOMï¼Œä¹Ÿä¸è¦æŠŠ gRPC å¡æ­»å¯¼è‡´æ•´ä½“ä¸å¯æ§ï¼š

**æ¨èé»˜è®¤ï¼šDrop æ¨¡å¼ï¼ˆå¯é…ç½®ï¼‰**
- é˜Ÿåˆ—æ»¡ â†’ ä¸¢å¼ƒæ–°äº‹ä»¶ï¼Œå¹¶è®°å½• `drop_total{reason="queue_full"}`ã€‚
- é€‚åˆï¼šé«˜é¢‘ syscall/kprobeï¼›é˜²æ­¢å¤§æµé‡æ‹–å®ç³»ç»Ÿã€‚

**å®¡è®¡å¼ºéœ€æ±‚ï¼šBlock æ¨¡å¼**
- é˜Ÿåˆ—æ»¡ â†’ é˜»å¡ readerï¼Œè®©ä¸Šæ¸¸è‡ªç„¶â€œé™é€Ÿâ€ã€‚
- é£é™©ï¼šå¯èƒ½å½±å“ Tetragon stream çš„å®æ—¶æ€§ï¼›éœ€è°¨æ…è¯„ä¼°ã€‚

**é‡‡æ ·ï¼ˆå¯é€‰ï¼‰**
- å¯¹é«˜é¢‘äº‹ä»¶ï¼ˆä¾‹å¦‚æŸäº› syscallï¼‰è¿›è¡Œé‡‡æ ·ï¼š`sample_ratio=0.1` æˆ–æŒ‰äº‹ä»¶ç±»å‹å•ç‹¬é…ç½®ã€‚

### 3.3 Kafka å†™å…¥ç­–ç•¥ï¼ˆååå…³é”®ï¼‰
- **å¼‚æ­¥å†™å…¥ + æ‰¹é‡**ï¼šæ˜¾è‘—æå‡ååã€‚
- **åˆ† topic**ï¼šæŠŠé«˜é¢‘ä¸ä½é¢‘äº‹ä»¶æ‹†å¼€ï¼Œé¿å…ç›¸äº’å½±å“ï¼š
  - `tetragon.process.exec`ï¼ˆä½é¢‘ä½†é«˜ä»·å€¼ï¼‰
  - `tetragon.syscall.*`ï¼ˆé«˜é¢‘ï¼‰
  - `tetragon.security.lsm`ï¼ˆç­–ç•¥ç›¸å…³ï¼‰
- **åˆ†åŒº key**ï¼šç”¨ `namespace|pod|binary` ç»„åˆåš hashï¼Œä¿è¯åŒä¸€å·¥ä½œè´Ÿè½½äº‹ä»¶èšåˆï¼Œä¾¿äºåç»­åˆ†æã€‚
- **ACK ç­–ç•¥**ï¼š
  - å®‰å…¨å®¡è®¡ï¼š`acks=all`
  - ååä¼˜å…ˆï¼š`acks=1`ï¼ˆéœ€è¦ç»“åˆä½ ä»¬å¯é æ€§è¦æ±‚ï¼‰
- **é”™è¯¯å¤„ç†**ï¼š
  - å†™å¤±è´¥ï¼šå»ºè®®è¿›å…¥ **DLQ topic**ï¼ˆå¦‚ `tetragon.dlq`ï¼‰æˆ–å†…å­˜é‡è¯•é˜Ÿåˆ—ï¼ˆå¸¦ä¸Šé™ï¼‰ã€‚

### 3.4 æ–­çº¿é‡è¿ï¼ˆå¿…é¡»ï¼‰
- gRPC æ–­å¼€æ—¶ï¼šæŒ‡æ•°é€€é¿ + jitter é‡è¿ï¼ˆ1s â†’ 2s â†’ 4s â€¦ ä¸Šé™ 30sï¼‰ã€‚
- é‡è¿æ¬¡æ•°/æœ€åä¸€æ¬¡é”™è¯¯åŸå› è¦ä½œä¸ºæŒ‡æ ‡è¾“å‡ºï¼Œä¾¿äºè¿ç»´ã€‚

---

## 4. é…ç½®è®¾è®¡ï¼ˆTopic åœ¨é…ç½®é‡Œåˆ›å»º/ç®¡ç†ï¼‰

### 4.1 é…ç½®æ–‡ä»¶ç¤ºä¾‹ï¼ˆYAMLï¼‰
> ä½ è¦æ±‚ï¼štopic ç”±é…ç½®å†³å®šã€å¯è‡ªåŠ¨åˆ›å»ºï¼ˆå¼€å…³ï¼‰

```yaml
tetragon:
  grpc_addr: "tetragon.kube-system.svc:54321"
  tls:
    enabled: false
  stream:
    max_queue: 50000
    drop_if_queue_full: true
    sample_ratio: 1.0

kafka:
  brokers: ["kafka-0.kafka:9092","kafka-1.kafka:9092"]
  client_id: "tetragon-consumer"
  acks: "all"
  compression: "snappy"
  batch:
    max_messages: 3000
    max_bytes: 1048576
    flush_interval_ms: 100
  writer_workers: 12
  topic_admin:
    auto_create: true
    partitions: 24
    replication_factor: 3

routing:
  topics:
    process_exec: "tetragon.process.exec"
    process_exit: "tetragon.process.exit"
    process_lsm: "tetragon.security.lsm"
    process_kprobe: "tetragon.syscall.kprobe"
    process_tracepoint: "tetragon.kernel.tracepoint"
    unknown: "tetragon.unknown"

  partition_key:
    mode: "deduplication"  # â­ å…³é”®ï¼šç”¨äºå»é‡çš„ key æ¨¡å¼ï¼ˆé…åˆ Compacted Topicï¼‰
    fields: ["k8s.namespace","k8s.pod","process.binary","process.pid","timestamp"]  # ç”Ÿæˆå”¯ä¸€ key
    separator: ":"

schema:
  version: 1
  mode: "stable_json"  # stable_json / raw_string_fallback
```

### 4.2 Topic è‡ªåŠ¨åˆ›å»ºï¼ˆå»ºè®®ï¼‰
- å¼€å¯ `topic_admin.auto_create=true`
- consumer å¯åŠ¨æ—¶éå† `routing.topics` åˆ›å»º topicï¼ˆè‹¥å·²å­˜åœ¨åˆ™è·³è¿‡ï¼‰
- æ³¨æ„ï¼šç”Ÿäº§ä¸­å¾ˆå¤š Kafka é›†ç¾¤ç¦æ­¢å®¢æˆ·ç«¯åˆ›å»º topicï¼Œéœ€è¦ä¸å¹³å°ç­–ç•¥ä¸€è‡´ã€‚

### 4.3 ç¯å¢ƒå˜é‡è¦†ç›–ï¼ˆæ¨èï¼‰
æ”¯æŒé€šè¿‡ç¯å¢ƒå˜é‡è¦†ç›–é…ç½®ï¼Œä¾¿äº K8s éƒ¨ç½²ï¼š

```bash
# Tetragon gRPC è¿æ¥
export TETRAGON_GRPC_ADDR="tetragon.kube-system.svc:54321"
export TETRAGON_TLS_ENABLED="false"

# Kafka é…ç½®
export KAFKA_BROKERS="kafka-0.kafka:9092,kafka-1.kafka:9092"
export KAFKA_CLIENT_ID="tetragon-consumer"
export KAFKA_ACKS="all"
export KAFKA_COMPRESSION="snappy"

# æ€§èƒ½è°ƒä¼˜
export STREAM_MAX_QUEUE="50000"
export STREAM_DROP_IF_QUEUE_FULL="true"
export KAFKA_WRITER_WORKERS="12"
export KAFKA_BATCH_MAX_MESSAGES="3000"
export KAFKA_BATCH_FLUSH_INTERVAL_MS="100"

# Topic è·¯ç”±ï¼ˆJSON æ ¼å¼ï¼‰
export ROUTING_TOPICS='{"process_exec":"tetragon.process.exec","process_exit":"tetragon.process.exit"}'

# æ—¥å¿—çº§åˆ«
export LOG_LEVEL="info"  # debug/info/warn/error
```

**ä¼˜å…ˆçº§**ï¼šç¯å¢ƒå˜é‡ > é…ç½®æ–‡ä»¶ > é»˜è®¤å€¼

### 4.4 é…ç½®éªŒè¯ï¼ˆå¯åŠ¨æ—¶ï¼‰
- éªŒè¯ gRPC åœ°å€æ ¼å¼
- éªŒè¯ Kafka brokers åˆ—è¡¨éç©º
- éªŒè¯ topic è·¯ç”±æ˜ å°„å®Œæ•´æ€§
- éªŒè¯é˜Ÿåˆ—å¤§å°ã€worker æ•°é‡åˆç†æ€§
- éªŒè¯ TLS/SASL è¯ä¹¦è·¯å¾„ï¼ˆå¦‚å¯ç”¨ï¼‰

---

## 5. äº‹ä»¶ â†’ Topic çš„â€œæœ€ä½³æ˜ å°„æ–¹æ¡ˆâ€ï¼ˆæ¨èï¼‰

### 5.1 æ¨èæ˜ å°„åŸåˆ™
1. **ä½é¢‘é«˜ä»·å€¼** ä¸ **é«˜é¢‘ä½ä»·å€¼** æ‹† Topicï¼ˆé¿å…æŠ¢èµ„æºï¼‰
2. **è¯­ä¹‰ç¨³å®š** çš„äº‹ä»¶å•ç‹¬ä¸€ä¸ª topicï¼ˆä¾¿äº schema æ¼”è¿›ï¼‰
3. éœ€è¦å®æ—¶å‘Šè­¦çš„äº‹ä»¶ï¼šä¿æŒ topic å°è€Œç²¾

### 5.2 å»ºè®® Topic é›†åˆ
- `tetragon.process.exec`ï¼šè¿›ç¨‹æ‰§è¡Œï¼ˆå‘Šè­¦æ ¸å¿ƒï¼‰
- `tetragon.process.exit`ï¼šè¿›ç¨‹é€€å‡ºï¼ˆå…³è”é—­ç¯ï¼‰
- `tetragon.security.lsm`ï¼šLSM å®‰å…¨äº‹ä»¶ï¼ˆé˜»æ–­/æƒé™æ£€æŸ¥ï¼‰
- `tetragon.syscall.kprobe`ï¼škprobe/syscallï¼ˆé«˜é¢‘ï¼Œå»ºè®®é‡‡æ ·/è¿‡æ»¤ï¼‰
- `tetragon.kernel.tracepoint`ï¼štracepointï¼ˆé€šå¸¸æ›´ç¨³å®šï¼‰
- `tetragon.unknown`ï¼šå…œåº•ï¼ˆé¿å…ä¸¢äº‹ä»¶ç±»å‹ï¼‰
- `tetragon.dlq`ï¼šå†™å…¥å¤±è´¥/åºåˆ—åŒ–å¤±è´¥/å­—æ®µå¼‚å¸¸

### 5.3 Partition keyï¼ˆæ¨èï¼‰
- é»˜è®¤ï¼š`namespace|pod|binary`
- è‹¥ä½ æ›´å…³å¿ƒâ€œè¿›ç¨‹æ ‘â€ï¼š`host|pid|tgid` ç»„åˆä¹Ÿå¯ï¼Œä½†è·¨ pod èšåˆè¾ƒå¼±ã€‚

---

## 6. äº‹ä»¶è§„èŒƒåŒ–ï¼ˆç¨³å®š JSON Schemaï¼Œå¼ºçƒˆæ¨èï¼‰

### 6.1 ä¸ºä»€ä¹ˆè¦è§„èŒƒåŒ–
protobuf äº‹ä»¶ç»“æ„ä¼šéšç‰ˆæœ¬æ¼”è¿›ï¼›ä¸‹æ¸¸æ¶ˆè´¹ï¼ˆFlink/ESï¼‰æ›´é€‚åˆç¨³å®š JSON schemaã€‚

### 6.2 æ¨èè¾“å‡º JSONï¼ˆç¤ºä¾‹ï¼‰
```json
{
  "schema_version": 1,
  "type": "process_exec",
  "ts": "2026-01-10T12:34:56.789Z",
  "node": "node-1",
  "k8s": { "namespace": "default", "pod": "nginx-123", "container": "nginx" },
  "process": { "pid": 1234, "ppid": 1, "uid": 0, "binary": "/bin/bash", "args": ["-c","curl","http://x"] },
  "labels": { "source": "tetragon", "cluster": "prod" },
  "raw": null
}
```

### 6.3 å…¼å®¹ç­–ç•¥ï¼ˆé¿å…å‡çº§ç‚¸è£‚ï¼‰
- å¿…å¤‡å­—æ®µç¼ºå¤±æ—¶ï¼šä¿åº•å¡«ç©ºå€¼ï¼Œä¿è¯ JSON å¯è§£æã€‚
- å¯¹æœªçŸ¥äº‹ä»¶ï¼šè¾“å‡º `type="unknown"` + `raw`ï¼ˆå­—ç¬¦ä¸²/å‹ç¼©å pb bytesï¼‰ã€‚
- schema ç‰ˆæœ¬ï¼š`schema_version` æ”¾åœ¨æ¯æ¡æ¶ˆæ¯ä¸­ï¼Œä¸‹æ¸¸æŒ‰ç‰ˆæœ¬å¤„ç†ã€‚

---

## 7. å¤§å¹¶å‘/æ€§èƒ½è°ƒä¼˜æ¸…å•ï¼ˆä½ å¯ä»¥æŒ‰è¿™ä¸ªå‹æµ‹ï¼‰

### 7.1 å…³é”®å‚æ•°å»ºè®®
- `max_queue`: 20k~200kï¼ˆç»“åˆå†…å­˜ä¸å³°å€¼ï¼‰
- `writer_workers`: 8~32ï¼ˆå…ˆä» 12/16 èµ·æ­¥ï¼‰
- `batch.max_messages`: 1000~5000
- `flush_interval_ms`: 50~200
- `compression`: snappy æˆ– lz4
- `acks`: allï¼ˆå¯é ï¼‰æˆ– 1ï¼ˆååï¼‰

### 7.2 å…¸å‹ç“¶é¢ˆå®šä½
1. **Kafka broker å†™å…¥ä¸Šé™**ï¼šåˆ†åŒºæ•°ä¸è¶³ã€ACK å¤ªä¸¥ã€ç£ç›˜æ…¢
2. **ç½‘ç»œå¸¦å®½**ï¼šconsumer â†’ broker ç½‘ç»œåå
3. **CPU**ï¼šJSON ç”Ÿæˆ/å­—æ®µæŠ½å–/åºåˆ—åŒ–
4. **é˜Ÿåˆ—æ°´ä½**ï¼šæŒç»­æ»¡è¯´æ˜ä¸‹æ¸¸å†™å…¥è·Ÿä¸ä¸Šï¼Œå¿…é¡»æ‰© worker æˆ–é™é‡‡æ ·

### 7.3 å»ºè®®çš„æŒ‡æ ‡ï¼ˆPrometheusï¼‰

**ååé‡æŒ‡æ ‡**
- `events_in_total{type=...}` - æ¥æ”¶çš„äº‹ä»¶æ€»æ•°ï¼ˆæŒ‰ç±»å‹ï¼‰
- `events_out_total{topic=...,status=...}` - å†™å…¥ Kafka çš„äº‹ä»¶æ•°ï¼ˆstatus: success/failedï¼‰
- `grpc_events_received_total` - gRPC æ¥æ”¶çš„äº‹ä»¶æ€»æ•°

**é˜Ÿåˆ—æŒ‡æ ‡**
- `queue_depth` - å½“å‰é˜Ÿåˆ—æ·±åº¦
- `queue_capacity` - é˜Ÿåˆ—å®¹é‡
- `queue_usage_ratio` - é˜Ÿåˆ—ä½¿ç”¨ç‡ï¼ˆqueue_depth / queue_capacityï¼‰

**ä¸¢å¼ƒä¸é‡‡æ ·æŒ‡æ ‡**
- `drops_total{reason=...}` - ä¸¢å¼ƒçš„äº‹ä»¶æ•°ï¼ˆreason: queue_full/sampled/invalidï¼‰
- `sampled_total{type=...}` - é‡‡æ ·çš„äº‹ä»¶æ•°ï¼ˆæŒ‰ç±»å‹ï¼‰

**å»¶è¿ŸæŒ‡æ ‡**
- `kafka_write_latency_ms_bucket{topic=...}` - Kafka å†™å…¥å»¶è¿Ÿï¼ˆHistogramï¼Œåˆ†æ¡¶ï¼‰
- `normalize_latency_ms_bucket{type=...}` - è§„èŒƒåŒ–å¤„ç†å»¶è¿Ÿ
- `route_latency_ms_bucket` - è·¯ç”±å†³ç­–å»¶è¿Ÿ

**Kafka å†™å…¥æŒ‡æ ‡**
- `kafka_write_bytes_total{topic=...}` - å†™å…¥ Kafka çš„å­—èŠ‚æ•°
- `kafka_write_messages_total{topic=...}` - å†™å…¥ Kafka çš„æ¶ˆæ¯æ•°
- `kafka_batch_size_bucket{topic=...}` - æ‰¹å¤„ç†å¤§å°åˆ†å¸ƒï¼ˆæŒ‰ topicï¼‰
- `kafka_batch_flush_total{topic=...}` - æ‰¹å¤„ç†åˆ·æ–°æ¬¡æ•°ï¼ˆæŒ‰ topicï¼‰
- `kafka_message_size_bytes_bucket{topic=...}` - å•æ¡æ¶ˆæ¯å¤§å°åˆ†å¸ƒ

**Topic çº§åˆ«æŒ‡æ ‡**
- `kafka_topic_write_rate{topic=...}` - Topic å†™å…¥é€Ÿç‡ï¼ˆmessages/secï¼‰
- `kafka_topic_write_bytes_rate{topic=...}` - Topic å†™å…¥å­—èŠ‚é€Ÿç‡ï¼ˆbytes/secï¼‰
- `kafka_topic_partition_count{topic=...}` - Topic åˆ†åŒºæ•°
- `kafka_topic_write_errors_total{topic=...,partition=...}` - Topic åˆ†åŒºå†™å…¥é”™è¯¯æ•°
- `kafka_topic_metadata_age_seconds{topic=...}` - Topic å…ƒæ•°æ®å¹´é¾„ï¼ˆç”¨äºæ£€æµ‹å…ƒæ•°æ®è¿‡æœŸï¼‰

**DLQï¼ˆæ­»ä¿¡é˜Ÿåˆ—ï¼‰æŒ‡æ ‡**
- `dlq_events_total{reason=...}` - å†™å…¥ DLQ çš„äº‹ä»¶æ•°ï¼ˆreason: write_failed/serialize_failed/invalid_schema/too_largeï¼‰
- `dlq_events_bytes_total` - å†™å…¥ DLQ çš„å­—èŠ‚æ€»æ•°
- `dlq_retry_attempts_total{reason=...}` - DLQ é‡è¯•æ¬¡æ•°
- `dlq_events_by_topic_total{topic=...,reason=...}` - æŒ‰åŸå§‹ topic åˆ†ç±»çš„ DLQ äº‹ä»¶æ•°

**é”™è¯¯æŒ‡æ ‡**
- `kafka_errors_total{error_type=...,topic=...}` - Kafka é”™è¯¯æ•°ï¼ˆerror_type: write/timeout/network/partition_leader_not_availableï¼‰
- `normalize_errors_total{event_type=...}` - è§„èŒƒåŒ–å¤±è´¥æ•°
- `grpc_errors_total{error_type=...}` - gRPC é”™è¯¯æ•°
- `route_errors_total{reason=...}` - è·¯ç”±é”™è¯¯æ•°ï¼ˆreason: unknown_topic/invalid_configï¼‰
- `serialize_errors_total{event_type=...}` - åºåˆ—åŒ–é”™è¯¯æ•°

**Topic ç®¡ç†æŒ‡æ ‡**
- `kafka_topic_create_total{status=...}` - Topic åˆ›å»ºæ¬¡æ•°ï¼ˆstatus: success/failedï¼‰
- `kafka_topic_create_duration_seconds` - Topic åˆ›å»ºè€—æ—¶
- `kafka_topic_exists{topic=...}` - Topic æ˜¯å¦å­˜åœ¨ï¼ˆ0/1ï¼‰
- `kafka_topic_metadata_refresh_total` - Topic å…ƒæ•°æ®åˆ·æ–°æ¬¡æ•°
- `kafka_topic_metadata_refresh_errors_total` - Topic å…ƒæ•°æ®åˆ·æ–°å¤±è´¥æ¬¡æ•°

**Topic å¥åº·åº¦æŒ‡æ ‡ï¼ˆProducer è§†è§’ï¼‰**
- `kafka_topic_partition_leader_available{topic=...,partition=...}` - åˆ†åŒº Leader æ˜¯å¦å¯ç”¨ï¼ˆ0/1ï¼‰
- `kafka_topic_partition_write_success_rate{topic=...,partition=...}` - åˆ†åŒºå†™å…¥æˆåŠŸç‡ï¼ˆ0-1ï¼‰
- `kafka_topic_unavailable_partitions{topic=...}` - Topic ä¸å¯ç”¨åˆ†åŒºæ•°
- `kafka_topic_write_throttle_total{topic=...}` - Topic å†™å…¥è¢«é™æµæ¬¡æ•°ï¼ˆå¦‚æœ broker é…ç½®äº†é™æµï¼‰

**æ³¨æ„**ï¼šä½œä¸º Producerï¼Œæ— æ³•ç›´æ¥ç›‘æ§ Consumer Lagï¼ˆç§¯å‹ï¼‰ï¼Œä½†å¯ä»¥é€šè¿‡ä»¥ä¸‹æ–¹å¼é—´æ¥è¯„ä¼°ï¼š
- ç›‘æ§å„ Topic å†™å…¥é€Ÿç‡ï¼Œå¦‚æœæŒç»­é«˜äºé¢„æœŸå¯èƒ½è¡¨ç¤ºä¸‹æ¸¸æ¶ˆè´¹æ…¢
- ç›‘æ§ DLQ å¢é•¿é€Ÿç‡ï¼Œå¦‚æœ DLQ æŒç»­å¢é•¿è¯´æ˜æœ‰æŒç»­å†™å…¥å¤±è´¥
- å»ºè®®åœ¨ Kafka é›†ç¾¤å±‚é¢ç›‘æ§ Consumer Lagï¼ˆä½¿ç”¨ Kafka è‡ªå¸¦çš„ JMX æŒ‡æ ‡æˆ–ç¬¬ä¸‰æ–¹å·¥å…·ï¼‰

### 7.4 å‘Šè­¦è§„åˆ™å»ºè®®ï¼ˆPrometheus AlertManagerï¼‰

```yaml
groups:
- name: tetragon_consumer
  interval: 30s
  rules:
  # é˜Ÿåˆ—å‘Šè­¦
  - alert: ConsumerQueueFull
    expr: queue_depth / queue_capacity > 0.9
    for: 5m
    labels:
      severity: warning
    annotations:
      summary: "Consumer queue is nearly full ({{ $value | humanizePercentage }})"
      description: "Queue usage: {{ $value | humanizePercentage }}, depth: {{ $labels.queue_depth }}, capacity: {{ $labels.queue_capacity }}"
      
  - alert: ConsumerHighDropRate
    expr: rate(drops_total[5m]) > 100
    for: 5m
    labels:
      severity: critical
    annotations:
      summary: "High event drop rate: {{ $value | humanize }} events/sec"
      description: "Drop rate: {{ $value | humanize }}/sec, reason: {{ $labels.reason }}"
      
  # Kafka å†™å…¥å‘Šè­¦
  - alert: ConsumerKafkaWriteFailure
    expr: rate(kafka_errors_total[5m]) > 10
    for: 5m
    labels:
      severity: critical
    annotations:
      summary: "Kafka write failures detected: {{ $value | humanize }}/sec"
      description: "Error type: {{ $labels.error_type }}, topic: {{ $labels.topic }}"
      
  - alert: ConsumerKafkaWriteLatencyHigh
    expr: histogram_quantile(0.99, kafka_write_latency_ms_bucket) > 1000
    for: 10m
    labels:
      severity: warning
    annotations:
      summary: "Kafka write latency P99 > 1s"
      description: "P99 latency: {{ $value }}ms for topic {{ $labels.topic }}"
      
  # Topic çº§åˆ«å‘Šè­¦
  - alert: ConsumerTopicWriteRateLow
    expr: kafka_topic_write_rate < 1
    for: 10m
    labels:
      severity: warning
    annotations:
      summary: "Topic {{ $labels.topic }} write rate is very low"
      description: "Write rate: {{ $value }} messages/sec"
      
  - alert: ConsumerTopicPartitionUnavailable
    expr: kafka_topic_unavailable_partitions > 0
    for: 2m
    labels:
      severity: critical
    annotations:
      summary: "Topic {{ $labels.topic }} has unavailable partitions"
      description: "Unavailable partitions: {{ $value }}"
      
  # DLQ å‘Šè­¦
  - alert: ConsumerDLQEventsHigh
    expr: rate(dlq_events_total[5m]) > 10
    for: 5m
    labels:
      severity: critical
    annotations:
      summary: "High DLQ event rate: {{ $value | humanize }}/sec"
      description: "DLQ events: {{ $value | humanize }}/sec, reason: {{ $labels.reason }}, original topic: {{ $labels.topic }}"
      
  - alert: ConsumerDLQGrowthRate
    expr: rate(dlq_events_bytes_total[10m]) > 1048576  # 1MB/sec
    for: 10m
    labels:
      severity: warning
    annotations:
      summary: "DLQ is growing rapidly"
      description: "DLQ growth rate: {{ $value | humanize1024 }}B/sec"
      
  # gRPC è¿æ¥å‘Šè­¦
  - alert: ConsumerGrpcDisconnected
    expr: grpc_stream_uptime_seconds == 0
    for: 1m
    labels:
      severity: critical
    annotations:
      summary: "gRPC stream disconnected"
      description: "gRPC stream has been disconnected for more than 1 minute"
      
  - alert: ConsumerGrpcFrequentReconnect
    expr: rate(grpc_reconnect_total[10m]) > 3
    for: 10m
    labels:
      severity: warning
    annotations:
      summary: "gRPC frequent reconnects"
      description: "Reconnect rate: {{ $value | humanize }}/10min"
      
  # è§„èŒƒåŒ–é”™è¯¯å‘Šè­¦
  - alert: ConsumerNormalizeErrorsHigh
    expr: rate(normalize_errors_total[5m]) > 50
    for: 5m
    labels:
      severity: warning
    annotations:
      summary: "High normalization error rate"
      description: "Normalize errors: {{ $value | humanize }}/sec for event type {{ $labels.event_type }}"
      
  # èµ„æºå‘Šè­¦
  - alert: ConsumerHighMemoryUsage
    expr: go_memstats_alloc_bytes > 2147483648  # 2GB
    for: 5m
    labels:
      severity: warning
    annotations:
      summary: "Consumer memory usage is high"
      description: "Memory allocated: {{ $value | humanize1024 }}B"
      
  - alert: ConsumerHighGoroutineCount
    expr: go_goroutines > 1000
    for: 5m
    labels:
      severity: warning
    annotations:
      summary: "Consumer has too many goroutines"
      description: "Goroutine count: {{ $value }}"
```

**è¿æ¥çŠ¶æ€æŒ‡æ ‡**
- `grpc_reconnect_total` - gRPC é‡è¿æ¬¡æ•°
- `grpc_stream_uptime_seconds` - gRPC stream è¿è¡Œæ—¶é•¿
- `kafka_producer_connected` - Kafka producer è¿æ¥çŠ¶æ€ï¼ˆ0/1ï¼‰

**èµ„æºä½¿ç”¨æŒ‡æ ‡**
- `process_uptime_seconds` - è¿›ç¨‹è¿è¡Œæ—¶é•¿
- `go_memstats_alloc_bytes` - å½“å‰å†…å­˜åˆ†é…ï¼ˆGo runtimeï¼‰
- `go_goroutines` - å½“å‰ goroutine æ•°é‡

---

## 8. åæœŸæ–°å¢äº‹ä»¶æ€ä¹ˆåšï¼ˆä½ å…³å¿ƒçš„é‡ç‚¹ï¼‰

ä½ è¦æ–°å¢äº‹ä»¶ï¼ˆä¾‹å¦‚æ–°å¢ `ProcessConnect` æˆ–æŸç±» tracepointï¼‰ï¼Œå»ºè®®æŒ‰ **â€œé…ç½®é©±åŠ¨ + æ’ä»¶å¼è§£æâ€** æ¥åšã€‚

### 8.1 æ–°å¢äº‹ä»¶çš„æœ€å°æ­¥éª¤ï¼ˆæ¨èæµç¨‹ï¼‰
1. **å‡çº§ Tetragon / pb**
   - æ‹‰å–æ–°ç‰ˆæœ¬ protobuf å¹¶é‡æ–°ç”Ÿæˆ `*.pb.go`
2. **åœ¨ Router é‡Œæ–°å¢ detectType åˆ†æ”¯**
   - è¯†åˆ«æ–°äº‹ä»¶ oneof / getter
3. **åœ¨ Normalizer æ–°å¢å­—æ®µæŠ½å–ï¼ˆå¯é€‰ï¼‰**
   - æŠŠæ–°äº‹ä»¶çš„å…³é”®å­—æ®µæŠ½å¹³åˆ°ç¨³å®š JSON
4. **åœ¨é…ç½®ä¸­æ–°å¢ topic æ˜ å°„**
   - `routing.topics.<new_type> = "tetragon.xxx"`
5. **ï¼ˆå¯é€‰ï¼‰å¯ç”¨ topic_admin è‡ªåŠ¨åˆ›å»º**
6. **å‹æµ‹ + è§‚å¯ŸæŒ‡æ ‡**
   - æ–°äº‹ä»¶æ˜¯å¦å¯¼è‡´ååæ³¢åŠ¨

### 8.2 â€œä¸ç”¨æ”¹ä»£ç ä¹Ÿèƒ½æ‰©å±•â€çš„æ–¹å¼ï¼ˆæ›´ä¸“ä¸šï¼‰
- **è§„åˆ™ 1ï¼šé»˜è®¤ unknown â†’ å…œåº• topic**
  - æ–°äº‹ä»¶æ¥äº†å³ä½¿ä½ æ²¡åŠ ä»£ç ï¼Œä¹Ÿä¸ä¼šä¸¢ï¼ˆä¼šè¿› unknownï¼‰
- **è§„åˆ™ 2ï¼šraw_fallback**
  - åœ¨ JSON ä¸­ä¿ç•™ `raw`ï¼ˆå­—ç¬¦ä¸²æˆ– base64 pb bytesï¼‰
  - ä¹‹åå†æ¸è¿›å¼è¡¥é½ normalizer

> æ¨èç­–ç•¥ï¼š
- **çŸ­æœŸ**ï¼šunknown topic + raw
- **ä¸­æœŸ**ï¼šä¸ºå…³é”®äº‹ä»¶è¡¥å­—æ®µæŠ½å– + ç‹¬ç«‹ topic
- **é•¿æœŸ**ï¼šç‰ˆæœ¬åŒ– schemaï¼ˆschema_versionï¼‰

### 8.3 æ¨èçš„ä»£ç ç»“æ„ï¼ˆä¾¿äºæ‰©å±•ï¼‰
- `router/detect.go`ï¼šåªè´Ÿè´£äº‹ä»¶ç±»å‹è¯†åˆ«
- `normalize/process_exec.go`ï¼šæ¯ç±»äº‹ä»¶ä¸€ä¸ªæ–‡ä»¶
- `schema/v1/*.go`ï¼šç¨³å®š schema è¾“å‡º
- `routing/config.go`ï¼šåªè¯»é…ç½®ï¼Œæ–°å¢ type åªæ”¹é…ç½®å’Œä¸€ä¸ª normalize æ–‡ä»¶

---

## 12. å®Œæ•´ä»£ç ç›®å½•ç»“æ„ï¼ˆæ¨èï¼‰

### 12.1 é¡¹ç›®æ ¹ç›®å½•ç»“æ„

```
tetragon-kafka-consumer/
â”œâ”€â”€ cmd/
â”‚   â””â”€â”€ consumer/
â”‚       â””â”€â”€ main.go                 # ç¨‹åºå…¥å£ï¼Œåˆå§‹åŒ–ã€ä¿¡å·å¤„ç†ã€ä¼˜é›…å…³é—­
â”œâ”€â”€ internal/
â”‚   â”œâ”€â”€ config/
â”‚   â”‚   â”œâ”€â”€ config.go               # é…ç½®ç»“æ„ä½“å®šä¹‰
â”‚   â”‚   â”œâ”€â”€ loader.go               # é…ç½®åŠ è½½ï¼ˆYAML + ç¯å¢ƒå˜é‡ï¼‰
â”‚   â”‚   â””â”€â”€ validator.go            # é…ç½®éªŒè¯
â”‚   â”œâ”€â”€ grpc/
â”‚   â”‚   â”œâ”€â”€ client.go               # gRPC å®¢æˆ·ç«¯å°è£…
â”‚   â”‚   â”œâ”€â”€ stream.go               # GetEvents stream ç®¡ç†
â”‚   â”‚   â””â”€â”€ reconnect.go            # æ–­çº¿é‡è¿é€»è¾‘ï¼ˆæŒ‡æ•°é€€é¿ï¼‰
â”‚   â”œâ”€â”€ router/
â”‚   â”‚   â”œâ”€â”€ detect.go               # äº‹ä»¶ç±»å‹è¯†åˆ«ï¼ˆswitch on oneofï¼‰
â”‚   â”‚   â””â”€â”€ router.go               # Topic è·¯ç”±å†³ç­–
â”‚   â”œâ”€â”€ normalize/
â”‚   â”‚   â”œâ”€â”€ normalizer.go           # è§„èŒƒåŒ–æ¥å£
â”‚   â”‚   â”œâ”€â”€ process_exec.go         # process_exec äº‹ä»¶è§„èŒƒåŒ–
â”‚   â”‚   â”œâ”€â”€ process_exit.go         # process_exit äº‹ä»¶è§„èŒƒåŒ–
â”‚   â”‚   â”œâ”€â”€ process_lsm.go          # LSM äº‹ä»¶è§„èŒƒåŒ–
â”‚   â”‚   â”œâ”€â”€ process_kprobe.go       # kprobe äº‹ä»¶è§„èŒƒåŒ–
â”‚   â”‚   â”œâ”€â”€ process_tracepoint.go   # tracepoint äº‹ä»¶è§„èŒƒåŒ–
â”‚   â”‚   â””â”€â”€ unknown.go              # æœªçŸ¥äº‹ä»¶å…œåº•å¤„ç†
â”‚   â”œâ”€â”€ schema/
â”‚   â”‚   â””â”€â”€ v1/
â”‚   â”‚       â”œâ”€â”€ schema.go           # ç¨³å®š JSON schema å®šä¹‰
â”‚   â”‚       â””â”€â”€ encoder.go          # JSON ç¼–ç å™¨
â”‚   â”œâ”€â”€ queue/
â”‚   â”‚   â”œâ”€â”€ queue.go                # å†…å­˜é˜Ÿåˆ—ï¼ˆå¸¦èƒŒå‹ç­–ç•¥ï¼‰
â”‚   â”‚   â””â”€â”€ sampler.go               # é‡‡æ ·å™¨ï¼ˆæŒ‰ç±»å‹/æ¯”ä¾‹ï¼‰
â”‚   â”œâ”€â”€ kafka/
â”‚   â”‚   â”œâ”€â”€ producer.go             # Kafka producer å°è£…
â”‚   â”‚   â”œâ”€â”€ writer.go               # æ‰¹é‡å†™å…¥ worker
â”‚   â”‚   â”œâ”€â”€ topic_admin.go          # Topic è‡ªåŠ¨åˆ›å»º/ç®¡ç†
â”‚   â”‚   â””â”€â”€ partition_key.go        # Partition key ç”Ÿæˆ
â”‚   â”œâ”€â”€ metrics/
â”‚   â”‚   â”œâ”€â”€ prometheus.go           # Prometheus æŒ‡æ ‡å®šä¹‰
â”‚   â”‚   â””â”€â”€ collector.go            # æŒ‡æ ‡æ”¶é›†å™¨
â”‚   â”œâ”€â”€ health/
â”‚   â”‚   â””â”€â”€ server.go               # HTTP å¥åº·æ£€æŸ¥ç«¯ç‚¹
â”‚   â”œâ”€â”€ leader/
â”‚   â”‚   â”œâ”€â”€ election.go             # K8s Leader Electionï¼ˆK8s ç¯å¢ƒï¼‰
â”‚   â”‚   â”œâ”€â”€ redis_lock.go           # Redis åˆ†å¸ƒå¼é”ï¼ˆä¸ä¾èµ– K8sï¼‰
â”‚   â”‚   â””â”€â”€ etcd_lock.go            # etcd åˆ†å¸ƒå¼é”ï¼ˆä¸ä¾èµ– K8sï¼‰
â”‚   â””â”€â”€ logger/
â”‚       â””â”€â”€ logger.go               # ç»“æ„åŒ–æ—¥å¿—ï¼ˆzap/logrusï¼‰
â”œâ”€â”€ pkg/
â”‚   â””â”€â”€ tetragon/                   # Tetragon protobuf ç”Ÿæˆä»£ç ï¼ˆå¯é€‰ï¼Œå¯å¼•ç”¨å®˜æ–¹åŒ…ï¼‰
â”‚       â””â”€â”€ api/
â”œâ”€â”€ configs/
â”‚   â”œâ”€â”€ config.yaml                 # é»˜è®¤é…ç½®æ–‡ä»¶
â”‚   â””â”€â”€ config.example.yaml         # é…ç½®ç¤ºä¾‹
â”œâ”€â”€ deployments/
â”‚   â”œâ”€â”€ k8s/
â”‚   â”‚   â”œâ”€â”€ deployment.yaml         # K8s Deployment
â”‚   â”‚   â”œâ”€â”€ daemonset.yaml          # K8s DaemonSetï¼ˆå¯é€‰ï¼‰
â”‚   â”‚   â”œâ”€â”€ configmap.yaml          # ConfigMap
â”‚   â”‚   â”œâ”€â”€ service.yaml            # Serviceï¼ˆå¥åº·æ£€æŸ¥ï¼‰
â”‚   â”‚   â””â”€â”€ serviceaccount.yaml     # ServiceAccount
â”‚   â””â”€â”€ helm/
â”‚       â””â”€â”€ tetragon-consumer/
â”‚           â”œâ”€â”€ Chart.yaml
â”‚           â”œâ”€â”€ values.yaml
â”‚           â””â”€â”€ templates/
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ generate-proto.sh           # protobuf ç”Ÿæˆè„šæœ¬
â”‚   â””â”€â”€ build.sh                    # æ„å»ºè„šæœ¬
â”œâ”€â”€ Dockerfile                       # å¤šé˜¶æ®µæ„å»º
â”œâ”€â”€ .dockerignore
â”œâ”€â”€ go.mod                           # Go æ¨¡å—ä¾èµ–
â”œâ”€â”€ go.sum
â”œâ”€â”€ Makefile                         # æ„å»º/æµ‹è¯•/è¿è¡Œå‘½ä»¤
â”œâ”€â”€ .gitignore
â”œâ”€â”€ README.md                        # é¡¹ç›®è¯´æ˜
â””â”€â”€ CHANGELOG.md                     # ç‰ˆæœ¬å˜æ›´æ—¥å¿—
```

### 12.2 æ ¸å¿ƒæ¨¡å—è¯´æ˜

#### `cmd/consumer/main.go`ï¼ˆä¸»ç¨‹åºï¼‰
- åˆå§‹åŒ–é…ç½®ã€æ—¥å¿—ã€metrics
- å¯åŠ¨ gRPC stream reader
- å¯åŠ¨ Kafka writer workers
- å¯åŠ¨å¥åº·æ£€æŸ¥ HTTP æœåŠ¡å™¨
- å¤„ç† SIGTERM/SIGINTï¼ˆä¼˜é›…å…³é—­ï¼‰
- ç­‰å¾…æ‰€æœ‰ goroutine é€€å‡º

#### `internal/grpc/`ï¼ˆgRPC å®¢æˆ·ç«¯ï¼‰
- `client.go`ï¼šè¿æ¥ç®¡ç†ã€TLS é…ç½®
- `stream.go`ï¼š`GetEvents` stream è®¢é˜…ã€äº‹ä»¶æ¥æ”¶å¾ªç¯
- `reconnect.go`ï¼šæŒ‡æ•°é€€é¿é‡è¿ï¼ˆ1s â†’ 2s â†’ 4s ... max 30sï¼‰

#### `internal/router/`ï¼ˆè·¯ç”±ï¼‰
- `detect.go`ï¼šä» protobuf äº‹ä»¶ä¸­è¯†åˆ«ç±»å‹ï¼ˆ`process_exec` / `process_exit` / `kprobe` ç­‰ï¼‰
- `router.go`ï¼šæ ¹æ®äº‹ä»¶ç±»å‹ + é…ç½®æ˜ å°„åˆ° Kafka topic

#### `internal/normalize/`ï¼ˆè§„èŒƒåŒ–ï¼‰
- æ¯ä¸ªäº‹ä»¶ç±»å‹ä¸€ä¸ªæ–‡ä»¶ï¼ŒæŠ½å–å…³é”®å­—æ®µåˆ°ç¨³å®š JSON schema
- `unknown.go`ï¼šæœªçŸ¥äº‹ä»¶å…œåº•ï¼ˆè¾“å‡º raw protobuf bytesï¼‰

#### `internal/kafka/`ï¼ˆKafka å†™å…¥ï¼‰
- `producer.go`ï¼šSarama/Confluent Kafka producer å°è£…
- `writer.go`ï¼šæ‰¹é‡å†™å…¥ workerï¼ˆæ¯ä¸ª worker ç‹¬ç«‹ batch bufferï¼‰
- `topic_admin.go`ï¼šå¯åŠ¨æ—¶è‡ªåŠ¨åˆ›å»º topicï¼ˆå¹‚ç­‰ï¼‰
- `partition_key.go`ï¼šæ ¹æ®é…ç½®ç”Ÿæˆ partition key

#### `internal/queue/`ï¼ˆé˜Ÿåˆ—ä¸èƒŒå‹ï¼‰
- `queue.go`ï¼šå¸¦å®¹é‡é™åˆ¶çš„å†…å­˜é˜Ÿåˆ—ï¼ˆchannel-basedï¼‰
- `sampler.go`ï¼šæŒ‰äº‹ä»¶ç±»å‹/é‡‡æ ·æ¯”ä¾‹è¿‡æ»¤

#### `internal/metrics/`ï¼ˆå¯è§‚æµ‹ï¼‰
- Prometheus æŒ‡æ ‡ï¼šååã€é˜Ÿåˆ—æ·±åº¦ã€dropã€å»¶è¿Ÿã€é”™è¯¯ã€é‡è¿

#### `internal/health/`ï¼ˆå¥åº·æ£€æŸ¥ï¼‰
- HTTP `/health`ï¼šè¿”å› gRPC è¿æ¥çŠ¶æ€ã€é˜Ÿåˆ—æ°´ä½ã€Kafka è¿æ¥çŠ¶æ€
- HTTP `/ready`ï¼šè¿”å›æ˜¯å¦å¯æ¥æ”¶æµé‡ï¼ˆç”¨äº K8s readiness probeï¼‰

#### `internal/leader/`ï¼ˆåˆ†å¸ƒå¼é”ï¼Œå¯é€‰ï¼‰
- `election.go`ï¼šK8s Leader Election å®ç°ï¼ˆK8s ç¯å¢ƒï¼Œä½¿ç”¨ K8s Lease APIï¼‰
- `redis_lock.go`ï¼šRedis åˆ†å¸ƒå¼é”å®ç°ï¼ˆä¸ä¾èµ– K8sï¼Œé€šç”¨æ–¹æ¡ˆï¼‰
- `etcd_lock.go`ï¼šetcd åˆ†å¸ƒå¼é”å®ç°ï¼ˆä¸ä¾èµ– K8sï¼Œé€šç”¨æ–¹æ¡ˆï¼‰
- åªæœ‰è·å¾—é”çš„ Pod æ‰§è¡Œå®é™…çš„ consumer é€»è¾‘ï¼Œé¿å…é‡å¤æ•°æ®

### 12.3 ä¾èµ–ç®¡ç†ï¼ˆgo.mod ç¤ºä¾‹ï¼‰

```go
module github.com/yourorg/tetragon-kafka-consumer

go 1.21

require (
    // Tetragon gRPC API
    github.com/cilium/tetragon/api v1.0.0
    
    // Kafka å®¢æˆ·ç«¯ï¼ˆäºŒé€‰ä¸€ï¼‰
    github.com/IBM/sarama v1.43.0          // æˆ–
    github.com/confluentinc/confluent-kafka-go/v2 v2.3.0
    
    // é…ç½®ç®¡ç†
    github.com/spf13/viper v1.18.0
    gopkg.in/yaml.v3 v3.0.1
    
    // gRPC
    google.golang.org/grpc v1.60.0
    google.golang.org/protobuf v1.31.0
    
    // æ—¥å¿—
    go.uber.org/zap v1.26.0                 // æˆ– github.com/sirupsen/logrus v1.9.3
    
    // æŒ‡æ ‡
    github.com/prometheus/client_golang v1.18.0
    
    // å·¥å…·
    golang.org/x/sync v0.5.0
    github.com/google/uuid v1.5.0
    
    // K8s å®¢æˆ·ç«¯ï¼ˆK8s Leader Election éœ€è¦ï¼Œå¯é€‰ï¼‰
    k8s.io/client-go v0.28.0
    k8s.io/api v0.28.0
    k8s.io/apimachinery v0.28.0
    
    // Redis å®¢æˆ·ç«¯ï¼ˆRedis åˆ†å¸ƒå¼é”ï¼Œå¯é€‰ï¼‰
    github.com/go-redis/redis/v8 v8.11.5
    
    // etcd å®¢æˆ·ç«¯ï¼ˆetcd åˆ†å¸ƒå¼é”ï¼Œå¯é€‰ï¼‰
    go.etcd.io/etcd/clientv3 v3.5.9
)
```

---

## 9. å®‰å…¨ä¸å¯é æ€§å»ºè®®ï¼ˆç”Ÿäº§å¿…çœ‹ï¼‰

### 9.1 å®‰å…¨é…ç½®
- **Kafka TLS/SASL**ï¼šå»ºè®®å¯ç”¨ï¼ˆç‰¹åˆ«æ˜¯è·¨ç½‘ç»œ/å¤šç§Ÿæˆ·ï¼‰
  ```yaml
  kafka:
    tls:
      enabled: true
      ca_cert: "/etc/kafka/ca.crt"
      client_cert: "/etc/kafka/client.crt"
      client_key: "/etc/kafka/client.key"
    sasl:
      enabled: true
      mechanism: "PLAIN"  # æˆ– SCRAM-SHA-256/SCRAM-SHA-512
      username: "tetragon-consumer"
      password_file: "/etc/kafka/password"  # ä» Secret æŒ‚è½½
  ```
- **gRPC TLS**ï¼šç”Ÿäº§ç¯å¢ƒå»ºè®®å¯ç”¨
  ```yaml
  tetragon:
    tls:
      enabled: true
      ca_cert: "/etc/tetragon/ca.crt"
      client_cert: "/etc/tetragon/client.crt"
      client_key: "/etc/tetragon/client.key"
  ```

### 9.2 å¯é æ€§ä¿éšœ
- **æ¶ˆæ¯å¤§å°é™åˆ¶**ï¼šé™åˆ¶å•æ¡ message æœ€å¤§å€¼ï¼ˆé¿å… args è¶…é•¿å¯¼è‡´ OOMï¼‰
  ```yaml
  kafka:
    max_message_bytes: 1048576  # 1MB
  ```
- **èµ„æºé™åˆ¶**ï¼šK8s ç»™ consumer è®¾ç½® requests/limitsï¼Œé¿å…æŠ¢å 
  ```yaml
  resources:
    requests:
      cpu: "500m"
      memory: "512Mi"
    limits:
      cpu: "2000m"
      memory: "2Gi"
  ```
- **DLQï¼ˆDead Letter Queueï¼‰**ï¼šå†™å¤±è´¥æˆ–åºåˆ—åŒ–å¤±è´¥å¿…é¡»å¯å›æ”¶ï¼ˆå®‰å…¨æ•°æ®ä¸èƒ½é»˜é»˜ä¸¢ï¼‰
  - æ‰€æœ‰å†™å…¥å¤±è´¥çš„äº‹ä»¶è¿›å…¥ `tetragon.dlq` topic
  - è®°å½•å¤±è´¥åŸå› ã€åŸå§‹äº‹ä»¶ã€æ—¶é—´æˆ³
  - å®šæœŸäººå·¥å®¡æŸ¥ DLQï¼Œä¿®å¤åé‡æ–°å¤„ç†

### 9.3 ä¼˜é›…å…³é—­ï¼ˆGraceful Shutdownï¼‰
- æ¥æ”¶ SIGTERM/SIGINT åï¼š
  1. åœæ­¢æ¥æ”¶æ–°äº‹ä»¶ï¼ˆå…³é—­ gRPC streamï¼‰
  2. ç­‰å¾…é˜Ÿåˆ—ä¸­çš„äº‹ä»¶å¤„ç†å®Œæˆï¼ˆè®¾ç½®è¶…æ—¶ï¼Œå¦‚ 30sï¼‰
  3. ç­‰å¾…æ‰€æœ‰ Kafka writer workers å®Œæˆå½“å‰ batch å¹¶ flush
  4. å…³é—­ Kafka producer
  5. è¾“å‡ºæœ€ç»ˆæŒ‡æ ‡
  6. é€€å‡º

```go
// ä¼ªä»£ç ç¤ºä¾‹
ctx, cancel := context.WithCancel(context.Background())
defer cancel()

// å¯åŠ¨æ‰€æœ‰ç»„ä»¶
go grpcReader(ctx)
go kafkaWriters(ctx)

// ç­‰å¾…ä¿¡å·
sigChan := make(chan os.Signal, 1)
signal.Notify(sigChan, syscall.SIGTERM, syscall.SIGINT)
<-sigChan

// ä¼˜é›…å…³é—­
cancel()
shutdownCtx, shutdownCancel := context.WithTimeout(context.Background(), 30*time.Second)
defer shutdownCancel()

// ç­‰å¾…é˜Ÿåˆ—æ¸…ç©º
waitForQueueEmpty(shutdownCtx)
// ç­‰å¾… writers å®Œæˆ
waitForWritersDone(shutdownCtx)
```

---

## 10. éƒ¨ç½²å»ºè®®ï¼ˆK8sï¼‰

### 10.0 âš ï¸ é‡è¦ï¼šåˆ†å¸ƒå¼éƒ¨ç½²ä¸é‡å¤æ•°æ®é—®é¢˜

#### 10.0.1 é—®é¢˜åˆ†æ

**åœºæ™¯ 1ï¼šDeployment å¤šå‰¯æœ¬ + åŒä¸€ Tetragon endpoint**
```
Pod-1 â”€â”€â”
Pod-2 â”€â”€â”¼â”€â”€> Tetragon gRPC (åŒä¸€ endpoint) â”€â”€> æ¯ä¸ª Pod æ”¶åˆ°ç›¸åŒäº‹ä»¶æµ
Pod-3 â”€â”€â”˜
         â†“
    æ¯ä¸ª Pod éƒ½å†™å…¥ Kafka
         â†“
    Kafka Topic: æ¯ä¸ªäº‹ä»¶è¢«å†™å…¥ 3 æ¬¡ï¼ˆé‡å¤ï¼ï¼‰
```

**é—®é¢˜**ï¼š
- å¤šä¸ª Pod è®¢é˜…åŒä¸€ä¸ª Tetragon gRPC endpoint æ—¶ï¼Œ**æ¯ä¸ª Pod éƒ½ä¼šæ”¶åˆ°å®Œæ•´çš„äº‹ä»¶æµ**
- å¯¼è‡´æ¯ä¸ªäº‹ä»¶è¢«å†™å…¥ Kafka **N æ¬¡**ï¼ˆN = Pod å‰¯æœ¬æ•°ï¼‰
- ä¸‹æ¸¸æ¶ˆè´¹è€…ä¼šæ”¶åˆ°é‡å¤æ•°æ®ï¼Œå½±å“åˆ†æå’Œå­˜å‚¨æˆæœ¬

**åœºæ™¯ 2ï¼šDaemonSet + èŠ‚ç‚¹çº§ Tetragon**
```
Node-1: Pod-1 â”€â”€> Tetragon-1 (æœ¬èŠ‚ç‚¹) â”€â”€> Kafka (ä¸é‡å¤)
Node-2: Pod-2 â”€â”€> Tetragon-2 (æœ¬èŠ‚ç‚¹) â”€â”€> Kafka (ä¸é‡å¤)
Node-3: Pod-3 â”€â”€> Tetragon-3 (æœ¬èŠ‚ç‚¹) â”€â”€> Kafka (ä¸é‡å¤)
```
**ä¼˜ç‚¹**ï¼šæ¯ä¸ª Pod åªè®¢é˜…æœ¬èŠ‚ç‚¹çš„ Tetragonï¼Œäº‹ä»¶ä¸é‡å¤

#### 10.0.2 è§£å†³æ–¹æ¡ˆå¯¹æ¯”ï¼ˆåˆ†å¸ƒå¼ Deployment æ¨¡å¼ï¼‰

> **â­ å¼ºçƒˆæ¨èï¼šæ–¹æ¡ˆ 1 - Kafka Compacted Topic + æ¶ˆæ¯ Key**
> 
> è¿™æ˜¯**æœ€ä½³æ–¹æ¡ˆ**ï¼Œåˆ©ç”¨ Kafka è‡ªèº«æœºåˆ¶è‡ªåŠ¨å»é‡ï¼Œä¸ä¾èµ–ä»»ä½•å¤–éƒ¨æœåŠ¡ï¼Œæ‰€æœ‰ Pod å¯åŒæ—¶å·¥ä½œï¼Œå®ç°ç®€å•ã€‚

| æ–¹æ¡ˆ | éƒ¨ç½²æ¨¡å¼ | ä¾èµ– | æ˜¯å¦é‡å¤ | é€‚ç”¨åœºæ™¯ | å¤æ‚åº¦ | æ¨èåº¦ |
|------|---------|------|---------|---------|--------|--------|
| **â­ æ–¹æ¡ˆ 1ï¼šKafka Compacted Topic + æ¶ˆæ¯ Key** | Deployment | âŒ ä¸ä¾èµ–å¤–éƒ¨ | âŒ ä¸é‡å¤ | **ä»»ä½•ç¯å¢ƒï¼Œåˆ©ç”¨ Kafka è‡ªèº«æœºåˆ¶** | â­â­ ä½ | â­â­â­â­â­ **å¼ºçƒˆæ¨èï¼ˆé¦–é€‰ï¼‰** |
| æ–¹æ¡ˆ 2ï¼šKafka äº‹åŠ¡æ€§ Producer | Deployment | âŒ ä¸ä¾èµ–å¤–éƒ¨ | âŒ ä¸é‡å¤ | éœ€è¦ exactly-once è¯­ä¹‰ | â­â­â­ ä¸­ | â­â­â­ å¤‡é€‰ |
| æ–¹æ¡ˆ 3ï¼šK8s Leader Election | Deployment | âš ï¸ ä¾èµ– K8s | âŒ ä¸é‡å¤ | K8s ç¯å¢ƒï¼Œæ— æ³•ä½¿ç”¨ Compacted Topic æ—¶ | â­â­â­ ä¸­ | â­â­ å¤‡é€‰ |
| æ–¹æ¡ˆ 4ï¼šå¤–éƒ¨åè°ƒæœåŠ¡ï¼ˆRedis/etcdï¼‰ | Deployment | âš ï¸ ä¾èµ–å¤–éƒ¨æœåŠ¡ | âŒ ä¸é‡å¤ | æ— æ³•ä½¿ç”¨ Kafka ç‰¹æ€§æ—¶ | â­â­â­ ä¸­ | â­â­ å¤‡é€‰ |
| æ–¹æ¡ˆ 5ï¼šä¸‹æ¸¸å»é‡ | Deployment | âŒ ä¸ä¾èµ–å¤–éƒ¨ | âš ï¸ éœ€è¦å»é‡é€»è¾‘ | ä¸‹æ¸¸å·²æœ‰å»é‡èƒ½åŠ› | â­â­ ä¸­ | â­â­ å¤‡é€‰ |

#### 10.0.3 æ¨èæ–¹æ¡ˆè¯¦è§£ï¼ˆåˆ†å¸ƒå¼ Deploymentï¼‰

> **â­ é¦–é€‰æ–¹æ¡ˆï¼šKafka Compacted Topic + æ¶ˆæ¯ Key**

**æ–¹æ¡ˆ 1ï¼šKafka Compacted Topic + æ¶ˆæ¯ Keyï¼ˆâ­ å¼ºçƒˆæ¨èï¼Œåˆ©ç”¨ Kafka è‡ªèº«æœºåˆ¶ï¼‰**

**æ¶æ„**ï¼š
```
Deployment (replicas: 3)
  â”œâ”€ Pod-1 â”€â”€â”
  â”œâ”€ Pod-2 â”€â”€â”¼â”€â”€> éƒ½è®¢é˜…åŒä¸€ Tetragon â”€â”€> éƒ½å†™å…¥ Kafkaï¼ˆä½¿ç”¨ç›¸åŒ Keyï¼‰
  â””â”€ Pod-3 â”€â”€â”˜
              â†“
    Kafka Compacted Topic
    (ç›¸åŒ Key çš„æ¶ˆæ¯è‡ªåŠ¨å»é‡ï¼Œåªä¿ç•™æœ€æ–°)
              â†“
         Kafka Topic (æ— é‡å¤)
```

**æ ¸å¿ƒåŸç†**ï¼š
- ä½¿ç”¨ **Kafka Compacted Topic**ï¼šKafka ä¼šè‡ªåŠ¨ä¿ç•™æ¯ä¸ª Key çš„æœ€æ–°æ¶ˆæ¯ï¼Œåˆ é™¤æ—§æ¶ˆæ¯
- æ‰€æœ‰ Pod ä½¿ç”¨**ç›¸åŒçš„æ¶ˆæ¯ Key**ï¼ˆåŸºäºäº‹ä»¶å”¯ä¸€æ ‡è¯†ç”Ÿæˆï¼‰
- å³ä½¿å¤šä¸ª Pod å†™å…¥ç›¸åŒäº‹ä»¶ï¼ŒKafka ä¹Ÿä¼šè‡ªåŠ¨å»é‡ï¼Œåªä¿ç•™æœ€åä¸€æ¡

**å®ç°è¦ç‚¹**ï¼š
1. **Topic é…ç½®ä¸º Compacted**ï¼š
   ```yaml
   kafka:
     topic_admin:
       cleanup_policy: "compact"  # å¯ç”¨ log compaction
       min_cleanable_dirty_ratio: 0.5
   ```

2. **æ¶ˆæ¯ Key ç”Ÿæˆ**ï¼ˆåŸºäºäº‹ä»¶å”¯ä¸€æ ‡è¯†ï¼‰ï¼š
   ```go
   // ç”Ÿæˆå”¯ä¸€çš„äº‹ä»¶ Key
   messageKey := fmt.Sprintf("%s:%s:%d:%d", 
       event.NodeName,
       event.Type,
       event.Process.Pid,
       event.Timestamp)
   ```

3. **Producer é…ç½®**ï¼š
   ```yaml
   kafka:
     producer:
       enable_idempotence: true  # å¯ç”¨å¹‚ç­‰æ€§ï¼ˆé˜²æ­¢ç½‘ç»œé‡è¯•é‡å¤ï¼‰
       acks: "all"                # ç¡®ä¿æ¶ˆæ¯æŒä¹…åŒ–
   ```

**ä¼˜ç‚¹**ï¼š
- âœ… **ä¸ä¾èµ–å¤–éƒ¨æœåŠ¡**ï¼šå®Œå…¨åˆ©ç”¨ Kafka è‡ªèº«æœºåˆ¶
- âœ… **è‡ªåŠ¨å»é‡**ï¼šKafka è‡ªåŠ¨å¤„ç†ï¼Œæ— éœ€ä¸‹æ¸¸å»é‡é€»è¾‘
- âœ… **æ— é‡å¤æ•°æ®**ï¼šKafka å±‚é¢ä¿è¯æ¯ä¸ª Key åªæœ‰æœ€æ–°æ¶ˆæ¯
- âœ… **çœŸæ­£çš„åˆ†å¸ƒå¼**ï¼šæ‰€æœ‰ Pod éƒ½åœ¨å·¥ä½œï¼Œæ— å•ç‚¹æ•…éšœ
- âœ… **é›¶åˆ‡æ¢ä¸­æ–­**ï¼šPod æ•…éšœä¸å½±å“å…¶ä»– Pod
- âœ… **å®ç°ç®€å•**ï¼šåªéœ€è¦é…ç½® Topic ä¸º Compactedï¼Œä½¿ç”¨æ¶ˆæ¯ Key

**ç¼ºç‚¹**ï¼š
- âš ï¸ **éœ€è¦åˆç†è®¾ç½® Key**ï¼šKey å¿…é¡»èƒ½å”¯ä¸€æ ‡è¯†äº‹ä»¶
- âš ï¸ **Compaction å»¶è¿Ÿ**ï¼šå»é‡ä¸æ˜¯å®æ—¶çš„ï¼Œæœ‰çŸ­æš‚å»¶è¿Ÿï¼ˆé€šå¸¸å‡ ç§’åˆ°å‡ åˆ†é’Ÿï¼‰
- âš ï¸ **å­˜å‚¨ç­–ç•¥**ï¼šCompacted Topic ä¼šä¿ç•™æ‰€æœ‰ Key çš„æœ€æ–°å€¼ï¼Œéœ€è¦åˆç†è®¾ç½® retention

**é€‚ç”¨åœºæ™¯**ï¼š
- âœ… **ç”Ÿäº§ç¯å¢ƒåˆ†å¸ƒå¼éƒ¨ç½²ï¼ˆå¼ºçƒˆæ¨èï¼‰**
- âœ… **ä»»ä½•éƒ¨ç½²ç¯å¢ƒï¼ˆä¸ä¾èµ– K8sã€Redisã€etcdï¼‰**
- âœ… **æ‰€æœ‰ Pod å¯åŒæ—¶å·¥ä½œï¼Œæ— å•ç‚¹æ•…éšœ**
- âœ… å¯ä»¥æ¥å— Compaction å»¶è¿Ÿï¼ˆé€šå¸¸å‡ ç§’åˆ°å‡ åˆ†é’Ÿï¼‰
- âœ… äº‹ä»¶æœ‰å”¯ä¸€æ ‡è¯†ï¼ˆnode + type + pid + timestampï¼‰

> **ğŸ’¡ ä¸ºä»€ä¹ˆé€‰æ‹©è¿™ä¸ªæ–¹æ¡ˆï¼Ÿ**
> - âœ… **æœ€ç®€å•**ï¼šåªéœ€é…ç½® Topic ä¸º Compactedï¼Œä½¿ç”¨æ¶ˆæ¯ Key
> - âœ… **æœ€å¯é **ï¼šåˆ©ç”¨ Kafka è‡ªèº«æœºåˆ¶ï¼Œä¸ä¾èµ–å¤–éƒ¨æœåŠ¡
> - âœ… **æœ€é«˜å¯ç”¨**ï¼šæ‰€æœ‰ Pod éƒ½åœ¨å·¥ä½œï¼Œæ— å•ç‚¹æ•…éšœ
> - âœ… **é›¶åˆ‡æ¢ä¸­æ–­**ï¼šPod æ•…éšœä¸å½±å“å…¶ä»– Pod
> - âœ… **è‡ªåŠ¨å»é‡**ï¼šKafka è‡ªåŠ¨å¤„ç†ï¼Œæ— éœ€é¢å¤–é€»è¾‘

---

**æ–¹æ¡ˆ 2ï¼šKafka äº‹åŠ¡æ€§ Producerï¼ˆExactly-Once è¯­ä¹‰ï¼Œå¤‡é€‰æ–¹æ¡ˆï¼‰**

**æ¶æ„**ï¼š
```
Deployment (replicas: 3)
  â”œâ”€ Pod-1 â”€â”€â”
  â”œâ”€ Pod-2 â”€â”€â”¼â”€â”€> åˆ†å¸ƒå¼é”ï¼ˆRedis/etcdï¼‰ â”€â”€> åªæœ‰è·å¾—é”çš„ Pod è®¢é˜… Tetragon
  â””â”€ Pod-3 â”€â”€â”˜
              â†“
         Leader Pod â”€â”€> Tetragon gRPC â”€â”€> Kafka (æ— é‡å¤)
         
Leader æ•…éšœæ—¶ï¼šé”è¿‡æœŸï¼Œå…¶ä»– Pod è‡ªåŠ¨ç«äº‰è·å¾—é”ï¼ˆé€šå¸¸åœ¨ 5-10 ç§’å†…å®Œæˆåˆ‡æ¢ï¼‰
```

**æ ¸å¿ƒåŸç†**ï¼š
- ä½¿ç”¨ Redis æˆ– etcd å®ç°åˆ†å¸ƒå¼é”
- å¤šä¸ª Pod ç«äº‰åŒä¸€ä¸ªé”ï¼Œåªæœ‰è·å¾—é”çš„ Pod æˆä¸º Leader
- Leader Pod è´Ÿè´£è®¢é˜… gRPC stream å¹¶å†™å…¥ Kafka
- å…¶ä»– Pod å¤„äº Standby çŠ¶æ€ï¼Œå®šæœŸå°è¯•è·å–é”

**å®ç°è¦ç‚¹**ï¼š
1. **åˆ†å¸ƒå¼é”å®ç°**ï¼š
   - Redisï¼šä½¿ç”¨ `SET key value NX EX ttl` å®ç°ï¼ˆæ¨èä½¿ç”¨ `github.com/go-redis/redis/v8`ï¼‰
   - etcdï¼šä½¿ç”¨ `etcd/clientv3/concurrency` åŒ…å®ç°
2. **é”ç»­æœŸæœºåˆ¶**ï¼šLeader Pod éœ€è¦å®šæœŸç»­æœŸé”ï¼ˆheartbeatï¼‰
3. **æ•…éšœåˆ‡æ¢**ï¼šLeader Pod æ•…éšœæ—¶ï¼Œé”è¿‡æœŸï¼Œå…¶ä»– Pod è‡ªåŠ¨ç«äº‰è·å¾—é”
4. **ä¼˜é›…åˆ‡æ¢**ï¼šLeader å¤±å»é”æ—¶ï¼Œä¼˜é›…å…³é—­ gRPC stream å’Œ Kafka writer

**ä¼˜ç‚¹**ï¼š
- âœ… **ä¸ä¾èµ– K8s**ï¼šå¯ä»¥åœ¨ä»»ä½•ç¯å¢ƒä½¿ç”¨ï¼ˆDockerã€VMã€è£¸æœºç­‰ï¼‰
- âœ… **æ— é‡å¤æ•°æ®**ï¼šåŒä¸€æ—¶åˆ»åªæœ‰ä¸€ä¸ª Pod åœ¨å†™å…¥
- âœ… **é«˜å¯ç”¨**ï¼šLeader æ•…éšœè‡ªåŠ¨åˆ‡æ¢ï¼Œé€šå¸¸ 5-10 ç§’æ¢å¤
- âœ… **æ”¯æŒæ°´å¹³æ‰©å±•**ï¼šå¯ä»¥å¢åŠ  Pod å‰¯æœ¬æ•°æé«˜å¯ç”¨æ€§
- âœ… **é€šç”¨æ–¹æ¡ˆ**ï¼šé€‚ç”¨äºå„ç§éƒ¨ç½²ç¯å¢ƒ

**ç¼ºç‚¹**ï¼š
- âš ï¸ Leader åˆ‡æ¢æ—¶æœ‰çŸ­æš‚ä¸­æ–­ï¼ˆ5-10 ç§’ï¼‰
- âš ï¸ éœ€è¦é¢å¤–çš„åè°ƒæœåŠ¡ï¼ˆRedis/etcdï¼‰
- âš ï¸ å®ç°å¤æ‚åº¦ä¸­ç­‰ï¼ˆéœ€è¦å¤„ç†é”ç»­æœŸå’Œåˆ‡æ¢é€»è¾‘ï¼‰

**é€‚ç”¨åœºæ™¯**ï¼š
- âœ… ç”Ÿäº§ç¯å¢ƒåˆ†å¸ƒå¼éƒ¨ç½²ï¼ˆä¸ä¾èµ– K8sï¼‰
- âœ… ä»»ä½•éƒ¨ç½²ç¯å¢ƒï¼ˆDockerã€VMã€è£¸æœºã€K8s ç­‰ï¼‰
- âœ… å·²æœ‰ Redis/etcd åŸºç¡€è®¾æ–½
- âœ… éœ€è¦é«˜å¯ç”¨ä½†å¯ä»¥æ¥å—çŸ­æš‚ä¸­æ–­

**æ–¹æ¡ˆ 3ï¼šK8s Leader Electionï¼ˆå¤‡é€‰æ–¹æ¡ˆï¼Œä»…å½“æ— æ³•ä½¿ç”¨ Compacted Topic æ—¶ï¼‰**

> **æ³¨æ„**ï¼šæ­¤æ–¹æ¡ˆä¾èµ– K8s çš„ Lease APIï¼Œä»…é€‚ç”¨äº K8s ç¯å¢ƒã€‚**ä¼˜å…ˆä½¿ç”¨æ–¹æ¡ˆ 1ï¼ˆKafka Compacted Topicï¼‰**ï¼Œåªæœ‰åœ¨æ— æ³•ä½¿ç”¨ Compacted Topic æ—¶æ‰è€ƒè™‘æ­¤æ–¹æ¡ˆã€‚

**æ–¹æ¡ˆ 4ï¼šå¤–éƒ¨åè°ƒæœåŠ¡ï¼ˆRedis/etcdï¼‰å®ç°åˆ†å¸ƒå¼é”ï¼ˆå¤‡é€‰æ–¹æ¡ˆï¼Œä»…å½“æ— æ³•ä½¿ç”¨ Compacted Topic æ—¶ï¼‰**

**æ–¹æ¡ˆ 5ï¼šKafka ç«¯å»é‡ï¼ˆä¸‹æ¸¸å»é‡ï¼Œå¤‡é€‰æ–¹æ¡ˆï¼‰**

**æ¶æ„**ï¼š
```
Deployment (replicas: 3)
  â”œâ”€ Pod-1 â”€â”€â”
  â”œâ”€ Pod-2 â”€â”€â”¼â”€â”€> éƒ½è®¢é˜…åŒä¸€ Tetragon â”€â”€> éƒ½å†™å…¥ Kafkaï¼ˆå¯èƒ½æœ‰é‡å¤ï¼‰
  â””â”€ Pod-3 â”€â”€â”˜
              â†“
         Kafka Topic (å¯èƒ½æœ‰é‡å¤æ¶ˆæ¯)
              â†“
         ä¸‹æ¸¸å»é‡ï¼ˆFlink/Spark/æ•°æ®åº“ï¼‰
```

**æ ¸å¿ƒåŸç†**ï¼š
- æ‰€æœ‰ Pod éƒ½è®¢é˜…åŒä¸€ä¸ª Tetragonï¼Œéƒ½å†™å…¥ Kafka
- é€šè¿‡æ¶ˆæ¯å»é‡é”®ï¼ˆdeduplication keyï¼‰æ ‡è¯†ç›¸åŒäº‹ä»¶
- ä¸‹æ¸¸æ¶ˆè´¹æ—¶åŸºäºå»é‡é”®å»é‡

**å®ç°è¦ç‚¹**ï¼š
1. **æ¶ˆæ¯å»é‡é”®ç”Ÿæˆ**ï¼šåŸºäºäº‹ä»¶å…³é”®å­—æ®µï¼ˆnode + type + pid + timestampï¼‰
2. **Kafka Producer å¹‚ç­‰æ€§**ï¼š`enable.idempotence=true`ï¼ˆé˜²æ­¢ç½‘ç»œé‡è¯•é‡å¤ï¼‰
3. **ä¸‹æ¸¸å»é‡**ï¼šFlink/Spark ä½¿ç”¨ `keyBy()` å»é‡ï¼Œæˆ–æ•°æ®åº“å”¯ä¸€ç´¢å¼•

**ä¼˜ç‚¹**ï¼š
- âœ… **çœŸæ­£çš„åˆ†å¸ƒå¼**ï¼šæ‰€æœ‰ Pod éƒ½åœ¨å·¥ä½œï¼Œæ— å•ç‚¹æ•…éšœ
- âœ… **æ— åˆ‡æ¢ä¸­æ–­**ï¼šPod æ•…éšœä¸å½±å“å…¶ä»– Pod
- âœ… **å®ç°ç›¸å¯¹ç®€å•**ï¼šä¸éœ€è¦ Leader Election é€»è¾‘

**ç¼ºç‚¹**ï¼š
- âš ï¸ **å¢åŠ å­˜å‚¨å¼€é”€**ï¼šKafka ä¸­å¯èƒ½æœ‰é‡å¤æ•°æ®ï¼ˆN å€ï¼‰
- âš ï¸ **å¢åŠ ç½‘ç»œå¼€é”€**ï¼šé‡å¤æ•°æ®åœ¨ç½‘ç»œä¸­ä¼ è¾“
- âš ï¸ **ä¸‹æ¸¸éœ€è¦å»é‡**ï¼šå¿…é¡»åœ¨æ¶ˆè´¹ç«¯å®ç°å»é‡é€»è¾‘
- âš ï¸ **å»é‡çª—å£è®¾ç½®**ï¼šéœ€è¦åˆç†è®¾ç½®å»é‡çª—å£ï¼Œé¿å…è¯¯åˆ 

**é€‚ç”¨åœºæ™¯**ï¼š
- âœ… ç”Ÿäº§ç¯å¢ƒåˆ†å¸ƒå¼éƒ¨ç½²
- âœ… ä¸‹æ¸¸å·²æœ‰å»é‡èƒ½åŠ›ï¼ˆFlink/Spark/æ•°æ®åº“ï¼‰
- âœ… å¯ä»¥æ¥å— Kafka å­˜å‚¨å¼€é”€å¢åŠ 
- âœ… éœ€è¦é›¶åˆ‡æ¢ä¸­æ–­

#### 10.0.4 ä»£ç è®¾è®¡å»ºè®®ï¼ˆåˆ†å¸ƒå¼ Deploymentï¼‰

**1. Kafka Compacted Topic å®ç°ï¼ˆâ­ æ¨èï¼Œåˆ©ç”¨ Kafka è‡ªèº«æœºåˆ¶ï¼‰**

```go
// internal/kafka/dedup_key.go
package kafka

import (
    "crypto/sha256"
    "encoding/hex"
    "fmt"
    
    "github.com/cilium/tetragon/api/v1/tetragon"
)

// GenerateDedupKey ç”Ÿæˆç”¨äºå»é‡çš„æ¶ˆæ¯ Key
// è¿™ä¸ª Key ä¼šç”¨äº Kafka Compacted Topicï¼Œç›¸åŒ Key çš„æ¶ˆæ¯ä¼šè‡ªåŠ¨å»é‡
func GenerateDedupKey(event *tetragon.GetEventsResponse) string {
    // åŸºäºäº‹ä»¶å”¯ä¸€æ ‡è¯†ç”Ÿæˆ Key
    // æ ¼å¼ï¼šnode:type:pid:timestamp
    var keyParts []string
    
    // Node åç§°
    if event.NodeName != "" {
        keyParts = append(keyParts, event.NodeName)
    } else {
        keyParts = append(keyParts, "unknown")
    }
    
    // äº‹ä»¶ç±»å‹
    eventType := detectEventType(event)
    keyParts = append(keyParts, eventType)
    
    // è¿›ç¨‹ä¿¡æ¯ï¼ˆå¦‚æœæœ‰ï¼‰
    if event.ProcessExec != nil {
        keyParts = append(keyParts, fmt.Sprintf("%d:%d", 
            event.ProcessExec.Process.Pid,
            event.ProcessExec.Process.StartTime))
    } else if event.ProcessExit != nil {
        keyParts = append(keyParts, fmt.Sprintf("%d:%d", 
            event.ProcessExit.Process.Pid,
            event.ProcessExit.Process.StartTime))
    } else {
        // å…¶ä»–äº‹ä»¶ç±»å‹ï¼Œä½¿ç”¨æ—¶é—´æˆ³
        keyParts = append(keyParts, fmt.Sprintf("%d", event.Time))
    }
    
    // æ—¶é—´æˆ³ï¼ˆçº³ç§’çº§ï¼Œç¡®ä¿å”¯ä¸€æ€§ï¼‰
    keyParts = append(keyParts, fmt.Sprintf("%d", event.Time))
    
    // ç»„åˆå¹¶ç”Ÿæˆ Hashï¼ˆå¯é€‰ï¼Œå¦‚æœ Key å¤ªé•¿ï¼‰
    key := fmt.Sprintf("%s", keyParts)
    if len(key) > 100 {
        // Key å¤ªé•¿ï¼Œä½¿ç”¨ Hash
        h := sha256.New()
        h.Write([]byte(key))
        return hex.EncodeToString(h.Sum(nil))[:32]
    }
    
    return key
}

// internal/kafka/producer.go
func (p *Producer) SendMessage(ctx context.Context, topic string, event *tetragon.GetEventsResponse, value []byte) error {
    // ç”Ÿæˆå»é‡ Key
    key := GenerateDedupKey(event)
    
    // å‘é€æ¶ˆæ¯ï¼ˆä½¿ç”¨ Keyï¼‰
    msg := &sarama.ProducerMessage{
        Topic: topic,
        Key:   sarama.StringEncoder(key),  // ä½¿ç”¨ Keyï¼ŒKafka Compacted Topic ä¼šè‡ªåŠ¨å»é‡
        Value: sarama.ByteEncoder(value),
        Headers: []sarama.RecordHeader{
            {Key: []byte("event_type"), Value: []byte(detectEventType(event))},
            {Key: []byte("node"), Value: []byte(event.NodeName)},
        },
    }
    
    _, _, err := p.producer.SendMessage(msg)
    return err
}

// internal/kafka/topic_admin.go
func (ta *TopicAdmin) CreateCompactedTopic(ctx context.Context, topic string, partitions int, replicationFactor int16) error {
    topicDetail := &sarama.TopicDetail{
        NumPartitions:     int32(partitions),
        ReplicationFactor: replicationFactor,
        ConfigEntries: map[string]*string{
            "cleanup.policy": stringPtr("compact"),  // å¯ç”¨ log compaction
            "min.cleanable.dirty.ratio": stringPtr("0.5"),
            "segment.ms": stringPtr("3600000"),  // 1 å°æ—¶
        },
    }
    
    return ta.admin.CreateTopic(topic, topicDetail, false)
}

func stringPtr(s string) *string {
    return &s
}
```

**2. Kafka äº‹åŠ¡æ€§ Producer å®ç°**

```go
// internal/kafka/transactional_producer.go
func NewTransactionalProducer(config *Config) (*TransactionalProducer, error) {
    saramaConfig := sarama.NewConfig()
    saramaConfig.Producer.Transactional.ID = config.Producer.TransactionalID  // æ¯ä¸ª Pod å”¯ä¸€
    saramaConfig.Producer.Idempotent = true
    saramaConfig.Producer.RequiredAcks = sarama.WaitForAll
    saramaConfig.Producer.MaxInFlightRequests = 1  // äº‹åŠ¡å¿…éœ€
    
    producer, err := sarama.NewSyncProducer(config.Brokers, saramaConfig)
    if err != nil {
        return nil, err
    }
    
    // åˆå§‹åŒ–äº‹åŠ¡
    err = producer.BeginTxn()
    if err != nil {
        return nil, err
    }
    
    return &TransactionalProducer{producer: producer}, nil
}

func (tp *TransactionalProducer) SendAndCommit(ctx context.Context, topic string, key string, value []byte) error {
    msg := &sarama.ProducerMessage{
        Topic: topic,
        Key:   sarama.StringEncoder(key),
        Value: sarama.ByteEncoder(value),
    }
    
    err := tp.producer.SendMessage(msg)
    if err != nil {
        tp.producer.AbortTxn()
        return err
    }
    
    // æäº¤äº‹åŠ¡
    return tp.producer.CommitTxn()
}
```

**3. K8s Leader Election å®ç°ï¼ˆK8s ç¯å¢ƒï¼Œä¾èµ– K8sï¼‰**

> **æ³¨æ„**ï¼šæ­¤æ–¹æ¡ˆä¾èµ– K8s Lease APIï¼Œä»…é€‚ç”¨äº K8s ç¯å¢ƒã€‚ä¼˜å…ˆè€ƒè™‘æ–¹æ¡ˆ 1ï¼ˆKafka Compacted Topicï¼‰ã€‚

```go
// internal/leader/election.go
package leader

import (
    "context"
    "os"
    "time"
    
    metav1 "k8s.io/apimachinery/pkg/apis/meta/v1"
    "k8s.io/client-go/kubernetes"
    "k8s.io/client-go/rest"
    "k8s.io/client-go/tools/leaderelection"
    "k8s.io/client-go/tools/leaderelection/resourcelock"
)

type Config struct {
    LeaseName      string
    LeaseNamespace string
    LeaseDuration  time.Duration
    RenewDeadline  time.Duration
    RetryPeriod   time.Duration
}

func RunWithLeaderElection(ctx context.Context, cfg Config, kubeClient kubernetes.Interface, runFunc func(context.Context)) {
    podName := os.Getenv("POD_NAME")
    if podName == "" {
        podName = os.Getenv("HOSTNAME")
    }
    
    lock := &resourcelock.LeaseLock{
        LeaseMeta: metav1.ObjectMeta{
            Name:      cfg.LeaseName,
            Namespace: cfg.LeaseNamespace,
        },
        Client: kubeClient.CoordinationV1(),
        LockConfig: resourcelock.ResourceLockConfig{
            Identity: podName,
        },
    }
    
    lec := leaderelection.LeaderElectionConfig{
        Lock:            lock,
        LeaseDuration:   cfg.LeaseDuration,
        RenewDeadline:   cfg.RenewDeadline,
        RetryPeriod:    cfg.RetryPeriod,
        Callbacks: leaderelection.LeaderCallbacks{
            OnStartedLeading: func(ctx context.Context) {
                log.Info("Became leader, starting consumer...")
                runFunc(ctx)
            },
            OnStoppedLeading: func() {
                log.Info("Lost leadership, stopping consumer...")
            },
            OnNewLeader: func(identity string) {
                if identity != podName {
                    log.Info("New leader elected", "leader", identity)
                }
            },
        },
    }
    
    leaderelection.RunOrDie(ctx, lec)
}

// cmd/consumer/main.go
func main() {
    config := loadConfig()
    
    // åˆå§‹åŒ– K8s clientï¼ˆç”¨äº Leader Electionï¼‰
    var kubeClient kubernetes.Interface
    if config.Deployment.LeaderElection.Enabled {
        kubeConfig, err := rest.InClusterConfig()
        if err != nil {
            log.Fatal("Failed to get in-cluster config", "error", err)
        }
        kubeClient, err = kubernetes.NewForConfig(kubeConfig)
        if err != nil {
            log.Fatal("Failed to create kube client", "error", err)
        }
    }
    
    ctx, cancel := context.WithCancel(context.Background())
    defer cancel()
    
    if config.Deployment.LeaderElection.Enabled {
        // Leader Election æ¨¡å¼
        leaderCfg := leader.Config{
            LeaseName:      config.Deployment.LeaderElection.LeaseName,
            LeaseNamespace: config.Deployment.LeaderElection.LeaseNamespace,
            LeaseDuration:  time.Duration(config.Deployment.LeaderElection.LeaseDurationSeconds) * time.Second,
            RenewDeadline:  time.Duration(config.Deployment.LeaderElection.RenewDeadlineSeconds) * time.Second,
            RetryPeriod:   2 * time.Second,
        }
        leader.RunWithLeaderElection(ctx, leaderCfg, kubeClient, func(ctx context.Context) {
            runConsumer(ctx, config)
        })
    } else {
        // ç›´æ¥è¿è¡Œï¼ˆå•å®ä¾‹æˆ–æµ‹è¯•ï¼‰
        runConsumer(ctx, config)
    }
}
```

**2. Redis åˆ†å¸ƒå¼é”å®ç°ï¼ˆä¸ä¾èµ– K8sï¼Œé€šç”¨æ–¹æ¡ˆï¼‰**

```go
// internal/leader/redis_lock.go
package leader

import (
    "context"
    "fmt"
    "os"
    "time"
    
    "github.com/go-redis/redis/v8"
)

type RedisLockConfig struct {
    RedisAddr     string
    RedisPassword string
    LockKey       string
    LockTTL       time.Duration  // é”çš„è¿‡æœŸæ—¶é—´
    RenewInterval time.Duration  // ç»­æœŸé—´éš”ï¼ˆåº”è¯¥ < LockTTL/2ï¼‰
}

type RedisLock struct {
    client        *redis.Client
    config        RedisLockConfig
    podID         string
    isLeader      bool
    stopRenew     chan struct{}
}

func NewRedisLock(config RedisLockConfig) *RedisLock {
    podID := os.Getenv("POD_NAME")
    if podID == "" {
        podID = os.Getenv("HOSTNAME")
    }
    if podID == "" {
        podID = fmt.Sprintf("pod-%d", os.Getpid())
    }
    
    rdb := redis.NewClient(&redis.Options{
        Addr:     config.RedisAddr,
        Password: config.RedisPassword,
        DB:       0,
    })
    
    return &RedisLock{
        client:    rdb,
        config:    config,
        podID:     podID,
        isLeader:  false,
        stopRenew: make(chan struct{}),
    }
}

// TryAcquireLock å°è¯•è·å–é”
func (rl *RedisLock) TryAcquireLock(ctx context.Context) (bool, error) {
    // SET key value NX EX ttl
    // NX: åªåœ¨ key ä¸å­˜åœ¨æ—¶è®¾ç½®
    // EX: è®¾ç½®è¿‡æœŸæ—¶é—´ï¼ˆç§’ï¼‰
    result, err := rl.client.SetNX(ctx, rl.config.LockKey, rl.podID, rl.config.LockTTL).Result()
    if err != nil {
        return false, err
    }
    
    if result {
        rl.isLeader = true
        // å¯åŠ¨ç»­æœŸ goroutine
        go rl.renewLock(ctx)
        return true, nil
    }
    
    return false, nil
}

// renewLock å®šæœŸç»­æœŸé”
func (rl *RedisLock) renewLock(ctx context.Context) {
    ticker := time.NewTicker(rl.config.RenewInterval)
    defer ticker.Stop()
    
    for {
        select {
        case <-ticker.C:
            // æ£€æŸ¥æ˜¯å¦è¿˜æ˜¯ Leaderï¼ˆé€šè¿‡ GET éªŒè¯ value æ˜¯å¦è¿˜æ˜¯è‡ªå·±çš„ podIDï¼‰
            currentOwner, err := rl.client.Get(ctx, rl.config.LockKey).Result()
            if err == redis.Nil {
                // é”å·²è¿‡æœŸï¼Œä¸å†æ˜¯ Leader
                rl.isLeader = false
                return
            }
            if err != nil {
                log.Error("Failed to check lock ownership", "error", err)
                continue
            }
            
            if currentOwner != rl.podID {
                // é”å·²è¢«å…¶ä»– Pod è·å–
                rl.isLeader = false
                return
            }
            
            // ç»­æœŸé”
            err = rl.client.Expire(ctx, rl.config.LockKey, rl.config.LockTTL).Err()
            if err != nil {
                log.Error("Failed to renew lock", "error", err)
                rl.isLeader = false
                return
            }
            
        case <-rl.stopRenew:
            return
        case <-ctx.Done():
            return
        }
    }
}

// ReleaseLock é‡Šæ”¾é”
func (rl *RedisLock) ReleaseLock(ctx context.Context) error {
    close(rl.stopRenew)
    
    // åªæœ‰é”çš„æ‹¥æœ‰è€…æ‰èƒ½é‡Šæ”¾
    currentOwner, err := rl.client.Get(ctx, rl.config.LockKey).Result()
    if err == redis.Nil {
        return nil  // é”å·²ä¸å­˜åœ¨
    }
    if err != nil {
        return err
    }
    
    if currentOwner == rl.podID {
        return rl.client.Del(ctx, rl.config.LockKey).Err()
    }
    
    return nil
}

// RunWithRedisLock ä½¿ç”¨ Redis é”è¿è¡Œå‡½æ•°
func RunWithRedisLock(ctx context.Context, config RedisLockConfig, runFunc func(context.Context)) {
    lock := NewRedisLock(config)
    defer lock.ReleaseLock(ctx)
    
    // å®šæœŸå°è¯•è·å–é”
    ticker := time.NewTicker(2 * time.Second)
    defer ticker.Stop()
    
    for {
        select {
        case <-ctx.Done():
            return
        case <-ticker.C:
            acquired, err := lock.TryAcquireLock(ctx)
            if err != nil {
                log.Error("Failed to acquire lock", "error", err)
                continue
            }
            
            if acquired {
                log.Info("Acquired lock, becoming leader", "pod", lock.podID)
                // è¿è¡Œå®é™…çš„ consumer é€»è¾‘
                runFunc(ctx)
                return
            }
        }
    }
}

// cmd/consumer/main.go
func main() {
    config := loadConfig()
    
    ctx, cancel := context.WithCancel(context.Background())
    defer cancel()
    
    if config.Deployment.LeaderElection.Enabled && config.Deployment.LeaderElection.Type == "redis" {
        // Redis åˆ†å¸ƒå¼é”æ¨¡å¼ï¼ˆä¸ä¾èµ– K8sï¼‰
        redisConfig := leader.RedisLockConfig{
            RedisAddr:     config.Deployment.LeaderElection.RedisAddr,
            RedisPassword: config.Deployment.LeaderElection.RedisPassword,
            LockKey:       "tetragon-consumer-leader",
            LockTTL:       15 * time.Second,
            RenewInterval: 5 * time.Second,
        }
        leader.RunWithRedisLock(ctx, redisConfig, func(ctx context.Context) {
            runConsumer(ctx, config)
        })
    } else if config.Deployment.LeaderElection.Enabled && config.Deployment.LeaderElection.Type == "k8s" {
        // K8s Leader Election æ¨¡å¼
        // ... (ä¹‹å‰çš„ K8s ä»£ç )
    } else {
        // ç›´æ¥è¿è¡Œï¼ˆå•å®ä¾‹æˆ–æµ‹è¯•ï¼‰
        runConsumer(ctx, config)
    }
}
```

**3. etcd åˆ†å¸ƒå¼é”å®ç°ï¼ˆä¸ä¾èµ– K8sï¼Œé€šç”¨æ–¹æ¡ˆï¼‰**

```go
// internal/leader/etcd_lock.go
package leader

import (
    "context"
    "time"
    
    "go.etcd.io/etcd/clientv3"
    "go.etcd.io/etcd/clientv3/concurrency"
)

func RunWithEtcdLock(ctx context.Context, etcdEndpoints []string, runFunc func(context.Context)) {
    cli, err := clientv3.New(clientv3.Config{
        Endpoints:   etcdEndpoints,
        DialTimeout: 5 * time.Second,
    })
    if err != nil {
        log.Fatal("Failed to connect to etcd", "error", err)
    }
    defer cli.Close()
    
    // åˆ›å»º sessionï¼ˆå¸¦ TTLï¼‰
    session, err := concurrency.NewSession(cli, concurrency.WithTTL(10))
    if err != nil {
        log.Fatal("Failed to create etcd session", "error", err)
    }
    defer session.Close()
    
    // åˆ›å»º mutex
    mutex := concurrency.NewMutex(session, "/tetragon-consumer-leader")
    
    // å°è¯•è·å–é”
    err = mutex.Lock(ctx)
    if err != nil {
        log.Fatal("Failed to acquire lock", "error", err)
    }
    defer mutex.Unlock(ctx)
    
    log.Info("Acquired lock, becoming leader")
    // è¿è¡Œå®é™…çš„ consumer é€»è¾‘
    runFunc(ctx)
}
```

**4. æ¶ˆæ¯å»é‡é”®ç”Ÿæˆï¼ˆæ–¹æ¡ˆ 3ï¼šKafka ç«¯å»é‡ï¼‰**

```go
// internal/kafka/dedup.go
func GenerateDedupKey(event *tetragon.GetEventsResponse) string {
    h := sha256.New()
    h.Write([]byte(event.NodeName))
    h.Write([]byte(event.Type))
    if event.ProcessExec != nil {
        h.Write([]byte(fmt.Sprintf("%d:%d", 
            event.ProcessExec.Process.Pid,
            event.ProcessExec.Process.StartTime)))
    }
    return hex.EncodeToString(h.Sum(nil))[:16]
}
```

#### 10.0.5 é…ç½®ç¤ºä¾‹ï¼ˆåˆ†å¸ƒå¼ Deploymentï¼‰

> **â­ æ¨èé…ç½®ï¼šKafka Compacted Topicï¼ˆæ–¹æ¡ˆ 1ï¼‰**

```yaml
# â­ æ–¹æ¡ˆ 1ï¼šKafka Compacted Topicï¼ˆæ¨èé…ç½®ï¼‰
kafka:
  brokers: ["kafka-0:9092", "kafka-1:9092"]
  client_id: "tetragon-consumer"
  producer:
    enable_idempotence: true  # å¯ç”¨å¹‚ç­‰æ€§ï¼ˆé˜²æ­¢ç½‘ç»œé‡è¯•é‡å¤ï¼‰
    acks: "all"               # ç¡®ä¿æ¶ˆæ¯æŒä¹…åŒ–
    compression: "snappy"
  topic_admin:
    auto_create: true
    cleanup_policy: "compact"  # â­ å…³é”®ï¼šå¯ç”¨ log compactionï¼Œè‡ªåŠ¨å»é‡
    min_cleanable_dirty_ratio: 0.5
    retention_ms: 604800000  # 7 days
    partitions: 24
    replication_factor: 3

routing:
  partition_key:
    mode: "deduplication"  # â­ å…³é”®ï¼šç”¨äºå»é‡çš„ key æ¨¡å¼
    fields: ["node", "type", "process.pid", "timestamp"]  # ç”Ÿæˆå”¯ä¸€ key
    separator: ":"

# å…¶ä»–é…ç½®ä¿æŒä¸å˜
tetragon:
  grpc_addr: "tetragon.kube-system.svc:54321"
  stream:
    max_queue: 50000
    drop_if_queue_full: true

# æ–¹æ¡ˆ 2ï¼šKafka äº‹åŠ¡æ€§ Producer
kafka:
  producer:
    transactional_id: "tetragon-consumer-${POD_NAME}"  # æ¯ä¸ª Pod å”¯ä¸€
    enable_idempotence: true
    acks: "all"
    max_in_flight_requests_per_connection: 1

# æ–¹æ¡ˆ 3ï¼šK8s Leader Election æ¨¡å¼ï¼ˆK8s ç¯å¢ƒï¼‰
deployment:
  mode: "deployment"
  leader_election:
    enabled: true
    type: "k8s"
    lease_name: "tetragon-consumer-leader"
    lease_namespace: "kube-system"
    lease_duration_seconds: 15
    renew_deadline_seconds: 10

# æ–¹æ¡ˆ 4ï¼šRedis åˆ†å¸ƒå¼é”æ¨¡å¼ï¼ˆä¸ä¾èµ– K8sï¼‰
deployment:
  mode: "deployment"
  leader_election:
    enabled: true
    type: "redis"
    redis_addr: "redis:6379"
    redis_password: ""
    lock_key: "tetragon-consumer-leader"
    lock_ttl_seconds: 15
    renew_interval_seconds: 5

# æ–¹æ¡ˆ 5ï¼šKafka ç«¯å»é‡ï¼ˆä¸‹æ¸¸å»é‡ï¼Œå¤‡é€‰ï¼‰
deployment:
  mode: "deployment"
  deduplication:
    enabled: true
    key_fields: ["node", "type", "process.pid", "timestamp"]
    window_seconds: 3600
```

#### 10.0.7 K8s RBAC é…ç½®ï¼ˆLeader Election å¿…éœ€ï¼‰

```yaml
# ServiceAccount
apiVersion: v1
kind: ServiceAccount
metadata:
  name: tetragon-consumer
  namespace: kube-system

---
# Roleï¼ˆLeader Election éœ€è¦ï¼‰
apiVersion: rbac.authorization.k8s.io/v1
kind: Role
metadata:
  name: tetragon-consumer-leader-election
  namespace: kube-system
rules:
- apiGroups: ["coordination.k8s.io"]
  resources: ["leases"]
  verbs: ["get", "list", "watch", "create", "update", "patch"]

---
# RoleBinding
apiVersion: rbac.authorization.k8s.io/v1
kind: RoleBinding
metadata:
  name: tetragon-consumer-leader-election
  namespace: kube-system
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: Role
  name: tetragon-consumer-leader-election
subjects:
- kind: ServiceAccount
  name: tetragon-consumer
  namespace: kube-system
```

#### 10.0.8 Deployment é…ç½®ç¤ºä¾‹ï¼ˆLeader Electionï¼‰

```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: tetragon-kafka-consumer
  namespace: kube-system
spec:
  replicas: 3  # å¤šå‰¯æœ¬ï¼ŒLeader Election ä¿è¯åªæœ‰ä¸€ä¸ªåœ¨å·¥ä½œ
  selector:
    matchLabels:
      app: tetragon-kafka-consumer
  template:
    metadata:
      labels:
        app: tetragon-kafka-consumer
    spec:
      serviceAccountName: tetragon-consumer  # ä½¿ç”¨ä¸Šé¢åˆ›å»ºçš„ SA
      containers:
      - name: consumer
        image: your-registry/tetragon-kafka-consumer:latest
        env:
        - name: POD_NAME
          valueFrom:
            fieldRef:
              fieldPath: metadata.name
        - name: TETRAGON_GRPC_ADDR
          value: "tetragon.kube-system.svc:54321"  # é›†ä¸­å¼ Tetragon
        - name: DEPLOYMENT_MODE
          value: "deployment"
        - name: LEADER_ELECTION_ENABLED
          value: "true"
        - name: LEADER_ELECTION_LEASE_NAME
          value: "tetragon-consumer-leader"
        - name: LEADER_ELECTION_LEASE_NAMESPACE
          value: "kube-system"
        resources:
          requests:
            cpu: "500m"
            memory: "512Mi"
          limits:
            cpu: "2000m"
            memory: "2Gi"
```

#### 10.0.6 æ¨èé€‰æ‹©ï¼ˆåˆ†å¸ƒå¼ Deploymentï¼‰

> **â­ å¼ºçƒˆæ¨èï¼šæ–¹æ¡ˆ 1 - Kafka Compacted Topic + æ¶ˆæ¯ Key**

| åœºæ™¯ | æ¨èæ–¹æ¡ˆ | ç†ç”± |
|------|---------|------|
| **â­ ç”Ÿäº§ç¯å¢ƒï¼ˆé¦–é€‰ï¼‰** | **æ–¹æ¡ˆ 1ï¼šKafka Compacted Topic** | **åˆ©ç”¨ Kafka è‡ªèº«æœºåˆ¶ã€ä¸ä¾èµ–å¤–éƒ¨ã€è‡ªåŠ¨å»é‡ã€çœŸæ­£åˆ†å¸ƒå¼ã€æœ€ç®€å•** |
| **éœ€è¦ Exactly-Once** | æ–¹æ¡ˆ 2ï¼šKafka äº‹åŠ¡æ€§ Producer | Kafka ä¿è¯ exactly-once è¯­ä¹‰ |
| **æ— æ³•ä½¿ç”¨ Compacted Topic** | æ–¹æ¡ˆ 3ï¼šK8s Leader Election | æ ‡å‡† K8s æœºåˆ¶ã€æ— é‡å¤ |
| **æ— æ³•ä½¿ç”¨ Compacted Topicï¼Œé K8s** | æ–¹æ¡ˆ 4ï¼šRedis/etcd åˆ†å¸ƒå¼é” | é€šç”¨æ–¹æ¡ˆï¼Œä¸ä¾èµ– K8s |
| **ä¸‹æ¸¸å·²æœ‰å»é‡èƒ½åŠ›** | æ–¹æ¡ˆ 5ï¼šä¸‹æ¸¸å»é‡ | é›¶åˆ‡æ¢ä¸­æ–­ã€çœŸæ­£åˆ†å¸ƒå¼ |

> **ğŸ’¡ å†³ç­–å»ºè®®**ï¼š
> 
> 1. **é¦–é€‰**ï¼š**æ–¹æ¡ˆ 1 - Kafka Compacted Topic + æ¶ˆæ¯ Key**
>    - âœ… æœ€ç®€å•ï¼šåªéœ€é…ç½® Topic ä¸º Compactedï¼Œä½¿ç”¨æ¶ˆæ¯ Key
>    - âœ… æœ€å¯é ï¼šåˆ©ç”¨ Kafka è‡ªèº«æœºåˆ¶ï¼Œä¸ä¾èµ–ä»»ä½•å¤–éƒ¨æœåŠ¡
>    - âœ… æœ€é«˜å¯ç”¨ï¼šæ‰€æœ‰ Pod éƒ½åœ¨å·¥ä½œï¼Œæ— å•ç‚¹æ•…éšœ
>    - âœ… è‡ªåŠ¨å»é‡ï¼šKafka è‡ªåŠ¨å¤„ç†ï¼Œæ— éœ€é¢å¤–é€»è¾‘
> 
> 2. **å¤‡é€‰**ï¼šåªæœ‰åœ¨ä»¥ä¸‹æƒ…å†µæ‰è€ƒè™‘å…¶ä»–æ–¹æ¡ˆ
>    - Kafka ç‰ˆæœ¬ä¸æ”¯æŒ Compacted Topicï¼ˆKafka 0.8.1+ æ”¯æŒï¼‰
>    - ä¸šåŠ¡è¦æ±‚å®æ—¶å»é‡ï¼ˆCompacted Topic æœ‰å»¶è¿Ÿï¼‰
>    - éœ€è¦ exactly-once è¯­ä¹‰ï¼ˆä½¿ç”¨æ–¹æ¡ˆ 2ï¼‰

### 10.1 éƒ¨ç½²æ¨¡å¼é€‰æ‹©ï¼ˆå¿«é€Ÿå‚è€ƒï¼‰

- æ¨èä»¥ **Deployment** è¿è¡Œ consumerï¼ˆå¯æ°´å¹³æ‰©å±•ï¼‰
- å¦‚æœä½ è¦å¤šå‰¯æœ¬ï¼š
  - éœ€è¦æ˜ç¡®æ¯ä¸ªå‰¯æœ¬æ˜¯å¦éƒ½è®¢é˜…åŒä¸€ä¸ª Tetragonï¼ˆä¼šé‡å¤ï¼‰
  - å¸¸è§åšæ³•ï¼šæ¯ä¸ª node ä¸€ä¸ª consumerï¼ˆDaemonSetï¼‰ï¼Œæˆ–åœ¨ consumer å†…æ”¯æŒâ€œä»…è®¢é˜…æœ¬èŠ‚ç‚¹ tetragonâ€
- æœ€ç®€å•ç¨³å®šï¼š**consumer ä¸ tetragon åŒèŠ‚ç‚¹ï¼ˆDaemonSetï¼‰**ï¼Œå†™ Kafkaã€‚

---

## 11. ä¸‹ä¸€æ­¥ï¼ˆå¦‚æœä½ è¦æˆ‘ç»§ç»­ç»™â€œæˆå“å·¥ç¨‹â€ï¼‰
æˆ‘å¯ä»¥åœ¨è¿™ä»½è®¾è®¡åŸºç¡€ä¸Šç»§ç»­è¡¥é½ï¼š
1. **å®Œæ•´å¯ç¼–è¯‘çš„ repoï¼ˆåŒ…å« protobuf ç”Ÿæˆè„šæœ¬ã€Dockerfileã€Helm valuesï¼‰**
2. **ç¨³å®š JSON schema v1 çš„å®Œæ•´å­—æ®µæŠ½å–ï¼ˆprocess/network/file/lsmï¼‰**
3. **Kafka topic admin è‡ªåŠ¨åˆ›å»ºå®ç°ï¼ˆå¸¦å¹‚ç­‰ï¼‰**
4. **Prometheus metrics + pprof æ€§èƒ½å‰–æå¼€å…³**

ä½ åªéœ€è¦å‘Šè¯‰æˆ‘ï¼š
- ä½ ä»¬ Kafka æ˜¯å¦å¯ç”¨ TLS/SASLï¼Ÿ
- ä½ æœ€æƒ³å…ˆæ”¯æŒå“ªäº›äº‹ä»¶ï¼šexec / connect / file / lsmï¼Ÿ
- ä½ ä»¬ä½¿ç”¨å“ªä¸ª Kafka å®¢æˆ·ç«¯åº“ï¼šSarama è¿˜æ˜¯ Confluentï¼Ÿ

---

## é™„å½• Aï¼šå®Œæ•´é…ç½®å‚è€ƒ

### A.1 å®Œæ•´ YAML é…ç½®ç¤ºä¾‹

```yaml
# Tetragon gRPC è¿æ¥é…ç½®
tetragon:
  grpc_addr: "tetragon.kube-system.svc:54321"
  tls:
    enabled: false
    ca_cert: "/etc/tetragon/ca.crt"
    client_cert: "/etc/tetragon/client.crt"
    client_key: "/etc/tetragon/client.key"
  stream:
    max_queue: 50000
    drop_if_queue_full: true
    sample_ratio: 1.0
    reconnect:
      initial_backoff_seconds: 1
      max_backoff_seconds: 30
      jitter: true

# Kafka é…ç½®
kafka:
  brokers: ["kafka-0.kafka:9092","kafka-1.kafka:9092"]
  client_id: "tetragon-consumer"
  acks: "all"  # all / 1 / 0
  compression: "snappy"  # none / gzip / snappy / lz4 / zstd
  max_message_bytes: 1048576  # 1MB
  batch:
    max_messages: 3000
    max_bytes: 1048576
    flush_interval_ms: 100
  writer_workers: 12
  tls:
    enabled: false
    ca_cert: "/etc/kafka/ca.crt"
    client_cert: "/etc/kafka/client.crt"
    client_key: "/etc/kafka/client.key"
  sasl:
    enabled: false
    mechanism: "PLAIN"  # PLAIN / SCRAM-SHA-256 / SCRAM-SHA-512
    username: "tetragon-consumer"
    password_file: "/etc/kafka/password"
  topic_admin:
    auto_create: true
    partitions: 24
    replication_factor: 3
    retention_ms: 604800000  # 7 days

# è·¯ç”±é…ç½®
routing:
  topics:
    process_exec: "tetragon.process.exec"
    process_exit: "tetragon.process.exit"
    process_lsm: "tetragon.security.lsm"
    process_kprobe: "tetragon.syscall.kprobe"
    process_tracepoint: "tetragon.kernel.tracepoint"
    process_connect: "tetragon.network.connect"
    process_dns: "tetragon.network.dns"
    unknown: "tetragon.unknown"
    dlq: "tetragon.dlq"
  partition_key:
    mode: "fields_concat"  # fields_concat / hash / random
    fields: ["k8s.namespace","k8s.pod","process.binary"]
    separator: "|"

# Schema é…ç½®
schema:
  version: 1
  mode: "stable_json"  # stable_json / raw_string_fallback
  include_raw: false  # æ˜¯å¦åœ¨ JSON ä¸­åŒ…å«åŸå§‹ protobuf bytes

# æ—¥å¿—é…ç½®
logger:
  level: "info"  # debug / info / warn / error
  format: "json"  # json / text
  output: "stdout"  # stdout / file
  file:
    path: "/var/log/consumer.log"
    max_size_mb: 100
    max_backups: 5
    max_age_days: 7

# ç›‘æ§é…ç½®
monitoring:
  enabled: true
  health_port: 8080
  metrics_port: 9090
  pprof_enabled: false
  pprof_port: 6060
```

### A.2 ç¯å¢ƒå˜é‡æ˜ å°„è¡¨

| é…ç½®è·¯å¾„ | ç¯å¢ƒå˜é‡ | ç¤ºä¾‹å€¼ |
|---------|---------|--------|
| `tetragon.grpc_addr` | `TETRAGON_GRPC_ADDR` | `tetragon.kube-system.svc:54321` |
| `tetragon.tls.enabled` | `TETRAGON_TLS_ENABLED` | `true` |
| `kafka.brokers` | `KAFKA_BROKERS` | `kafka-0:9092,kafka-1:9092` |
| `kafka.client_id` | `KAFKA_CLIENT_ID` | `tetragon-consumer` |
| `kafka.acks` | `KAFKA_ACKS` | `all` |
| `kafka.compression` | `KAFKA_COMPRESSION` | `snappy` |
| `kafka.writer_workers` | `KAFKA_WRITER_WORKERS` | `12` |
| `stream.max_queue` | `STREAM_MAX_QUEUE` | `50000` |
| `stream.drop_if_queue_full` | `STREAM_DROP_IF_QUEUE_FULL` | `true` |
| `logger.level` | `LOG_LEVEL` | `info` |

---

## é™„å½• Bï¼šæ€§èƒ½åŸºå‡†å‚è€ƒ

### B.1 å…¸å‹æ€§èƒ½æŒ‡æ ‡ï¼ˆå‚è€ƒå€¼ï¼‰

| åœºæ™¯ | QPS | å»¶è¿Ÿ (P99) | CPU | å†…å­˜ |
|------|-----|-----------|-----|------|
| ä½è´Ÿè½½ | 1k/s | < 50ms | 200m | 256Mi |
| ä¸­è´Ÿè½½ | 10k/s | < 100ms | 500m | 512Mi |
| é«˜è´Ÿè½½ | 50k/s | < 200ms | 1000m | 1Gi |
| æé«˜è´Ÿè½½ | 100k/s+ | < 500ms | 2000m | 2Gi+ |

**æ³¨æ„**ï¼šå®é™…æ€§èƒ½å–å†³äºäº‹ä»¶ç±»å‹ã€Kafka é…ç½®ã€ç½‘ç»œæ¡ä»¶ç­‰å› ç´ ã€‚

### B.2 è°ƒä¼˜å»ºè®®

- **CPU ç“¶é¢ˆ**ï¼šå¢åŠ  `writer_workers`ã€å¯ç”¨å‹ç¼©ã€ä¼˜åŒ– JSON åºåˆ—åŒ–
- **å†…å­˜ç“¶é¢ˆ**ï¼šé™ä½ `max_queue`ã€å¯ç”¨é‡‡æ ·ã€é™åˆ¶æ¶ˆæ¯å¤§å°
- **ç½‘ç»œç“¶é¢ˆ**ï¼šå¢åŠ  Kafka åˆ†åŒºæ•°ã€ä¼˜åŒ– batch å¤§å°ã€ä½¿ç”¨å‹ç¼©
- **Kafka ç“¶é¢ˆ**ï¼šå¢åŠ åˆ†åŒºæ•°ã€è°ƒæ•´ ACK ç­–ç•¥ã€ä¼˜åŒ– broker é…ç½®

---

## é™„å½• Cï¼šç‰ˆæœ¬å…¼å®¹æ€§

### C.1 Tetragon ç‰ˆæœ¬æ”¯æŒ
- **æœ€ä½ç‰ˆæœ¬**ï¼šTetragon v1.0+
- **æ¨èç‰ˆæœ¬**ï¼šTetragon v1.9+ï¼ˆæ”¯æŒæœ€æ–°äº‹ä»¶ç±»å‹ï¼‰
- **API å…¼å®¹æ€§**ï¼šåŸºäº `github.com/cilium/tetragon/api` protobuf å®šä¹‰

### C.2 Go ç‰ˆæœ¬è¦æ±‚
- **æœ€ä½ç‰ˆæœ¬**ï¼šGo 1.21
- **æ¨èç‰ˆæœ¬**ï¼šGo 1.22+

### C.3 Kafka ç‰ˆæœ¬æ”¯æŒ
- **Sarama å®¢æˆ·ç«¯**ï¼šKafka 0.8.2+
- **Confluent å®¢æˆ·ç«¯**ï¼šKafka 0.9.0+
- **æ¨è**ï¼šKafka 2.8+ï¼ˆæ”¯æŒæ›´å¥½çš„æ€§èƒ½ç‰¹æ€§ï¼‰

---

## é™„å½• Dï¼šå¸¸è§é—®é¢˜ FAQ

**Q: ä¸ºä»€ä¹ˆé€‰æ‹© gRPC è€Œä¸æ˜¯ç›´æ¥è¯»å–æ–‡ä»¶ï¼Ÿ**
A: gRPC æµå¼è®¢é˜…å®æ—¶æ€§æ›´å¥½ï¼Œä¸ä¾èµ–æ–‡ä»¶ç³»ç»Ÿï¼Œé€‚åˆå®¹å™¨åŒ–éƒ¨ç½²ã€‚

**Q: å¤šå‰¯æœ¬éƒ¨ç½²ä¼šå¯¼è‡´äº‹ä»¶é‡å¤å—ï¼Ÿ**
A: å¦‚æœæ‰€æœ‰å‰¯æœ¬è®¢é˜…åŒä¸€ä¸ª Tetragonï¼Œä¼šé‡å¤ã€‚å»ºè®®ä½¿ç”¨ DaemonSet æ¨¡å¼ï¼Œæ¯ä¸ªèŠ‚ç‚¹ä¸€ä¸ª consumerã€‚

**Q: å¦‚ä½•ä¿è¯äº‹ä»¶ä¸ä¸¢å¤±ï¼Ÿ**
A: ä½¿ç”¨ `acks=all`ã€å¯ç”¨ DLQã€ç›‘æ§ drop æŒ‡æ ‡ã€‚ä½†é«˜é¢‘ syscall äº‹ä»¶å»ºè®®é‡‡æ ·ï¼Œé¿å…å­˜å‚¨æˆæœ¬è¿‡é«˜ã€‚

**Q: æ”¯æŒé…ç½®çƒ­é‡è½½å—ï¼Ÿ**
A: å½“å‰è®¾è®¡ä¸æ”¯æŒï¼Œéœ€è¦é‡å¯ã€‚å¦‚éœ€çƒ­é‡è½½ï¼Œå¯æ‰©å±•æ”¯æŒ SIGHUP ä¿¡å·æˆ– HTTP APIã€‚

**Q: å¦‚ä½•è°ƒè¯•æ€§èƒ½é—®é¢˜ï¼Ÿ**
A: å¯ç”¨ pprofã€æŸ¥çœ‹ Prometheus æŒ‡æ ‡ã€åˆ†æé˜Ÿåˆ—æ°´ä½å’Œ Kafka å†™å…¥å»¶è¿Ÿã€‚

---

## é™„å½• Eï¼šç›¸å…³èµ„æº

- [Tetragon å®˜æ–¹æ–‡æ¡£](https://github.com/cilium/tetragon)
- [Tetragon API å‚è€ƒ](https://github.com/cilium/tetragon/tree/main/api)
- [Sarama Kafka å®¢æˆ·ç«¯](https://github.com/IBM/sarama)
- [Confluent Kafka Go å®¢æˆ·ç«¯](https://github.com/confluentinc/confluent-kafka-go)
- [Prometheus æŒ‡æ ‡æœ€ä½³å®è·µ](https://prometheus.io/docs/practices/naming/)
